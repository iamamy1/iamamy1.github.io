<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Node Embeddings | iamamy1 の blog</title>
    <meta name="generator" content="VuePress 1.8.2">
    <link rel="icon" href="/logo.jpg">
    <meta name="description" content="欢迎来到小菜鸡iamamy1的世界">
    
    <link rel="preload" href="/assets/css/0.styles.36434bf9.css" as="style"><link rel="preload" href="/assets/js/app.a00dae28.js" as="script"><link rel="preload" href="/assets/js/2.6ba3a72f.js" as="script"><link rel="preload" href="/assets/js/18.24d615f3.js" as="script"><link rel="prefetch" href="/assets/js/10.e51717da.js"><link rel="prefetch" href="/assets/js/11.651dca46.js"><link rel="prefetch" href="/assets/js/12.332bc178.js"><link rel="prefetch" href="/assets/js/13.d1af2c08.js"><link rel="prefetch" href="/assets/js/14.3fbb62f4.js"><link rel="prefetch" href="/assets/js/15.8bd24c17.js"><link rel="prefetch" href="/assets/js/16.7dae6182.js"><link rel="prefetch" href="/assets/js/17.afacc0fe.js"><link rel="prefetch" href="/assets/js/19.f751f11e.js"><link rel="prefetch" href="/assets/js/20.c5cc9911.js"><link rel="prefetch" href="/assets/js/21.a2d5669f.js"><link rel="prefetch" href="/assets/js/22.53ab2a35.js"><link rel="prefetch" href="/assets/js/23.d7a40619.js"><link rel="prefetch" href="/assets/js/24.90f1b562.js"><link rel="prefetch" href="/assets/js/25.d4a5fabc.js"><link rel="prefetch" href="/assets/js/26.96bbd2b5.js"><link rel="prefetch" href="/assets/js/27.e49ad878.js"><link rel="prefetch" href="/assets/js/28.7a2ea5f6.js"><link rel="prefetch" href="/assets/js/29.530ce587.js"><link rel="prefetch" href="/assets/js/3.a9289617.js"><link rel="prefetch" href="/assets/js/30.efa68a3a.js"><link rel="prefetch" href="/assets/js/31.b7e538fb.js"><link rel="prefetch" href="/assets/js/32.54c00d3f.js"><link rel="prefetch" href="/assets/js/33.b36f9a0d.js"><link rel="prefetch" href="/assets/js/34.973766ac.js"><link rel="prefetch" href="/assets/js/35.7e73613f.js"><link rel="prefetch" href="/assets/js/36.e20c7498.js"><link rel="prefetch" href="/assets/js/37.64e3aad9.js"><link rel="prefetch" href="/assets/js/38.369a3474.js"><link rel="prefetch" href="/assets/js/4.65af8b10.js"><link rel="prefetch" href="/assets/js/5.c049ea05.js"><link rel="prefetch" href="/assets/js/6.f8c29748.js"><link rel="prefetch" href="/assets/js/7.38e440a5.js"><link rel="prefetch" href="/assets/js/8.c3872073.js"><link rel="prefetch" href="/assets/js/9.cc17c434.js">
    <link rel="stylesheet" href="/assets/css/0.styles.36434bf9.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">iamamy1 の blog</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">
  首页
</a></div><div class="nav-item"><a href="/studybook/lc/lc1.html" class="nav-link">
  学习笔记
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="传送门" class="dropdown-title"><span class="title">传送门</span> <span class="arrow down"></span></button> <button type="button" aria-label="传送门" class="mobile-dropdown-title"><span class="title">传送门</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>
          在线编辑
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="https://tinypng.com/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  图片压缩
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></li><li class="dropdown-item"><h4>
          在线服务
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="https://www.aliyun.com/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  阿里云
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-subitem"><a href="https://cloud.tencent.com/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  腾讯云
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></li><li class="dropdown-item"><h4>
          博客指南
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="https://juejin.im/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  掘金
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-subitem"><a href="https://blog.csdn.net/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  CSDN
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></li></ul></div></div><div class="nav-item"><a href="/guide/notes/about.html" class="nav-link">
  关于
</a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">
  首页
</a></div><div class="nav-item"><a href="/studybook/lc/lc1.html" class="nav-link">
  学习笔记
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="传送门" class="dropdown-title"><span class="title">传送门</span> <span class="arrow down"></span></button> <button type="button" aria-label="传送门" class="mobile-dropdown-title"><span class="title">传送门</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>
          在线编辑
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="https://tinypng.com/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  图片压缩
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></li><li class="dropdown-item"><h4>
          在线服务
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="https://www.aliyun.com/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  阿里云
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-subitem"><a href="https://cloud.tencent.com/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  腾讯云
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></li><li class="dropdown-item"><h4>
          博客指南
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="https://juejin.im/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  掘金
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-subitem"><a href="https://blog.csdn.net/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  CSDN
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></li></ul></div></div><div class="nav-item"><a href="/guide/notes/about.html" class="nav-link">
  关于
</a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>LeetCode刷题</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>python基础</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>动手学深度学习_代码总结</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>Machine Learning with Graphs</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/studybook/GraphsML/01-intro.html" class="sidebar-link">Introduction</a></li><li><a href="/studybook/GraphsML/02-tradition-ml.html" class="sidebar-link">Traditional Methods for Machine Learning in Graphs</a></li><li><a href="/studybook/GraphsML/03-nodeemb.html" aria-current="page" class="active sidebar-link">Node Embeddings</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/studybook/GraphsML/03-nodeemb.html#_3-1-graph-representation-learning" class="sidebar-link">3.1 Graph Representation Learning</a></li><li class="sidebar-sub-header"><a href="/studybook/GraphsML/03-nodeemb.html#_3-2-node-embeddings-encoder-and-decoder" class="sidebar-link">3.2 Node Embeddings: Encoder and Decoder</a></li><li class="sidebar-sub-header"><a href="/studybook/GraphsML/03-nodeemb.html#_3-3-random-walk-approaches-for-node-embeddings" class="sidebar-link">3.3 Random Walk Approaches for Node Embeddings</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/studybook/GraphsML/03-nodeemb.html#random-walk-strategies" class="sidebar-link">Random walk strategies</a></li></ul></li><li class="sidebar-sub-header"><a href="/studybook/GraphsML/03-nodeemb.html#_3-4-embedding-entire-graphs" class="sidebar-link">3.4 Embedding Entire Graphs</a></li><li class="sidebar-sub-header"><a href="/studybook/GraphsML/03-nodeemb.html#_3-5-summary" class="sidebar-link">3.5 Summary</a></li></ul></li><li><a href="/studybook/GraphsML/06-GNN1.html" class="sidebar-link">Graph Neural Networks</a></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>前端学习笔记</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>学习总结</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>其他</span> <span class="arrow right"></span></p> <!----></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="node-embeddings"><a href="#node-embeddings" class="header-anchor">#</a> Node Embeddings</h1> <p><em><strong>Core idea:</strong> Embed nodes so that distances in embedding space reflect node similarities in the original network.</em></p> <h2 id="_3-1-graph-representation-learning"><a href="#_3-1-graph-representation-learning" class="header-anchor">#</a> 3.1 Graph Representation Learning</h2> <p>alleviates the need to do feature engineering every single time</p> <p><strong>Goal:</strong> Efficient task-independent feature learning for machine learning with graphs</p> <p><strong>Embedding Task:</strong> map nodes into an embedding space</p> <h2 id="_3-2-node-embeddings-encoder-and-decoder"><a href="#_3-2-node-embeddings-encoder-and-decoder" class="header-anchor">#</a> 3.2 Node Embeddings: Encoder and Decoder</h2> <p><strong>Goal</strong> is to encode nodes so that similarity in the embedding space approximates similarity in the graph</p> <ol><li><u>Encoder</u> maps from nodes to embeddings</li> <li>Define a node <u>similarity function</u></li> <li><u>Decoder</u> maps from embeddings to the similarity score</li> <li><u>Optimize the parameters of the encoder</u> so that  similarity in the embedding space approximates similarity in the original network</li></ol> <p><strong>Two Key Components</strong></p> <ul><li><strong>Encoder:</strong> maps each node to a low-dimensional vector</li> <li><strong>Similarity function:</strong> specifies how the relationships in vector space map to the relationships in the original network</li></ul> <p><strong>&quot;Shallow&quot; Encodeing</strong></p> <ul><li>Simplest encoding approach: Encoder is just an embedding-lookup</li> <li>Each node is assigned a unique embedding vector</li></ul> <p><strong>Encoder + Decoder Framework</strong></p> <ul><li>Shallow encoder: embedding lookup</li> <li>Optimize parameters</li> <li>Decoder: based on node similarity</li></ul> <h2 id="_3-3-random-walk-approaches-for-node-embeddings"><a href="#_3-3-random-walk-approaches-for-node-embeddings" class="header-anchor">#</a> 3.3 Random Walk Approaches for Node Embeddings</h2> <p><strong>Non-linear functions used to produce predicted probabilities</strong></p> <ul><li>Softmax function: Turns vector of K real values (model predictions) into K probabilities that sum to 1</li> <li>Sigmoid function: S-shaped function that turns real values into the range of (0, 1)</li></ul> <p><strong>Random Walk</strong></p> <ul><li>Given a graph and a starting point, we select a neighbor of it at random, and move to this neighbor; then we select a neighbor of this point at random, and move to it, etc. The (random) sequence of points visited this way is a random walk on the graph</li></ul> <p><strong>Unsupervised Feature Learning</strong></p> <p><strong>Random Walk Optimization</strong></p> <ol><li>Run short fixed-length random walks: starting from each node u in the graph using some random walk strategy <em>R</em></li> <li>For each node u collect N_R(u) , the multiset* of nodes visited on random walks starting from u</li> <li>Optimize embeddings according to: Given node u, predict its neighbors N_R(u)</li></ol> <p>But doing this naively is too expensive, especially the normalization term from the softmax,  so we have to approximate it, the solution is negative sampling</p> <p><strong>Negative Sampling</strong></p> <ul><li>Sample K negative nodes each with prob. proportional to its degree</li> <li>Two considerations for K
<ol><li>Higher K gives more robust estimates</li> <li>Higher K corresponds to higher bias on negative events in practice</li></ol></li></ul> <p><strong>Stochastic Gradient Descent(Optimize embeddings)</strong></p> <ul><li><strong>Gradient Descent</strong>: a simple way to minimize objective function</li></ul> <ol><li>Initialize Z_i at some randomized value for all i</li> <li>Iterate until convergence</li></ol> <ul><li><strong>Stochastic Gradient Descent</strong>: Instead of evaluating gradients over all examples, evaluate it for each individual training example</li></ul> <ol><li>Initialize Z_i at some randomized value for all i</li> <li>Iterate until convergence</li></ol> <h3 id="random-walk-strategies"><a href="#random-walk-strategies" class="header-anchor">#</a> Random walk strategies</h3> <p><strong>node2vec: Biased Walks</strong></p> <ul><li>use flexible, biased random walks that can trade off between local and global views of the network</li> <li>Two classic strategie:
<ol><li>BFS : Micro-view of neighbourhood</li> <li>DFS : Macro-view of neighbourhood</li></ol></li></ul> <p><strong>node2vec algorithm</strong></p> <ol><li>Compute random walk probabilities</li> <li>Simulate R random walks of length L starting from each node u</li> <li>Optimize the node2vec objective using Stochastic Gradient Descent</li></ol> <ul><li>Linear-time complexity</li> <li>All 3 steps are individually parallelizable</li></ul> <p><strong>Other Random Walk Ideas</strong></p> <ul><li><p>Different kinds of biased random walks:</p> <ol><li><p>Based on node attributes</p></li> <li><p>Based on learned weights</p></li></ol></li> <li><p>Alternative optimization schemes:</p> <ol><li>Directly optimize based on 1-hop and 2-hop random walk probabilities</li></ol></li> <li><p>Network preprocessing techniques:</p> <ol><li>Run random walks on modified versions of the original network</li></ol></li></ul> <h2 id="_3-4-embedding-entire-graphs"><a href="#_3-4-embedding-entire-graphs" class="header-anchor">#</a> 3.4 Embedding Entire Graphs</h2> <p><strong>Goal:</strong> Want to embed a subgraph or an entire graph</p> <p><strong>Tasks:</strong></p> <ul><li>Classifying toxic vs. non-toxic molecules</li> <li>Identifying anomalous graphs</li></ul> <p><strong>Approach 1:Embed nodes and sum/avg them</strong></p> <ul><li>Run a standard graph embedding technique <em>on</em> the (sub)graph G</li> <li>Then just sum (or average) the node embeddings in the (sub)graph G</li></ul> <p><strong>Approach 2:Create super-node that spans the (sub) graph and then embed that node</strong></p> <ul><li>Introduce a “virtual node” to represent the (sub)graph and run a standard graph embedding technique</li></ul> <p><strong>Approach 3: Anonymous Walk Embeddings</strong></p> <ul><li><p>States in anonymous walks correspond to the index of the first time we visited the node in a random walk</p></li> <li><p>Agnostic to the identity of the nodes visited (hence anonymous)</p></li> <li><p>Number of anonymous walks grows exponentially(There are 5 anonymous walks of length 3: 111, 112, 121, 122, 123)</p></li> <li><p>New idea: Learn Walk Embedding: Rather than simply represent each walk by the fraction of times it occurs, we learn embedding Z_i of anonymous walk W_i</p></li></ul> <ol><li>Idea 1: Sample the anon. walks and represent the graph as fraction of times each anon walk occurs</li> <li>Idea 2: Embed anonymous walks, concatenate their embeddings to get a graph embedding</li></ol> <h2 id="_3-5-summary"><a href="#_3-5-summary" class="header-anchor">#</a> 3.5 Summary</h2> <p>We discussed graph representation learning, a way to learn node and graph embeddings for downstream tasks, without feature engineering.</p> <p><strong>Encoder-decoder framework:</strong></p> <ul><li>Encoder: embedding lookup</li> <li>Decoder: predict score based on embedding to match node similarity</li></ul> <p><strong>Node similarity measure: (biased) random walk</strong></p> <ul><li>Examples: DeepWalk, Node2Vec</li></ul> <p><strong>Extension to Graph embedding</strong></p> <ul><li>Node embedding aggregation</li> <li>Anonymous Walk Embeddings</li></ul></div> <footer class="page-edit"><!----> <div class="last-updated"><span class="prefix">更新时间:</span> <span class="time">10/7/2021, 5:16:28 PM</span></div></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/studybook/GraphsML/02-tradition-ml.html" class="prev">
        Traditional Methods for Machine Learning in Graphs
      </a></span> <span class="next"><a href="/studybook/GraphsML/06-GNN1.html">
        Graph Neural Networks
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.a00dae28.js" defer></script><script src="/assets/js/2.6ba3a72f.js" defer></script><script src="/assets/js/18.24d615f3.js" defer></script>
  </body>
</html>

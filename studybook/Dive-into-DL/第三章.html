<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>第三章 | iamamy1 の blog</title>
    <meta name="generator" content="VuePress 1.8.2">
    <link rel="icon" href="/logo.jpg">
    <meta name="description" content="欢迎来到小菜鸡iamamy1的世界">
    
    <link rel="preload" href="/assets/css/0.styles.36434bf9.css" as="style"><link rel="preload" href="/assets/js/app.a00dae28.js" as="script"><link rel="preload" href="/assets/js/2.6ba3a72f.js" as="script"><link rel="preload" href="/assets/js/14.3fbb62f4.js" as="script"><link rel="prefetch" href="/assets/js/10.e51717da.js"><link rel="prefetch" href="/assets/js/11.651dca46.js"><link rel="prefetch" href="/assets/js/12.332bc178.js"><link rel="prefetch" href="/assets/js/13.d1af2c08.js"><link rel="prefetch" href="/assets/js/15.8bd24c17.js"><link rel="prefetch" href="/assets/js/16.7dae6182.js"><link rel="prefetch" href="/assets/js/17.afacc0fe.js"><link rel="prefetch" href="/assets/js/18.24d615f3.js"><link rel="prefetch" href="/assets/js/19.f751f11e.js"><link rel="prefetch" href="/assets/js/20.c5cc9911.js"><link rel="prefetch" href="/assets/js/21.a2d5669f.js"><link rel="prefetch" href="/assets/js/22.53ab2a35.js"><link rel="prefetch" href="/assets/js/23.d7a40619.js"><link rel="prefetch" href="/assets/js/24.90f1b562.js"><link rel="prefetch" href="/assets/js/25.d4a5fabc.js"><link rel="prefetch" href="/assets/js/26.96bbd2b5.js"><link rel="prefetch" href="/assets/js/27.e49ad878.js"><link rel="prefetch" href="/assets/js/28.7a2ea5f6.js"><link rel="prefetch" href="/assets/js/29.530ce587.js"><link rel="prefetch" href="/assets/js/3.a9289617.js"><link rel="prefetch" href="/assets/js/30.efa68a3a.js"><link rel="prefetch" href="/assets/js/31.b7e538fb.js"><link rel="prefetch" href="/assets/js/32.54c00d3f.js"><link rel="prefetch" href="/assets/js/33.b36f9a0d.js"><link rel="prefetch" href="/assets/js/34.973766ac.js"><link rel="prefetch" href="/assets/js/35.7e73613f.js"><link rel="prefetch" href="/assets/js/36.e20c7498.js"><link rel="prefetch" href="/assets/js/37.64e3aad9.js"><link rel="prefetch" href="/assets/js/38.369a3474.js"><link rel="prefetch" href="/assets/js/4.65af8b10.js"><link rel="prefetch" href="/assets/js/5.c049ea05.js"><link rel="prefetch" href="/assets/js/6.f8c29748.js"><link rel="prefetch" href="/assets/js/7.38e440a5.js"><link rel="prefetch" href="/assets/js/8.c3872073.js"><link rel="prefetch" href="/assets/js/9.cc17c434.js">
    <link rel="stylesheet" href="/assets/css/0.styles.36434bf9.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">iamamy1 の blog</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">
  首页
</a></div><div class="nav-item"><a href="/studybook/lc/lc1.html" class="nav-link">
  学习笔记
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="传送门" class="dropdown-title"><span class="title">传送门</span> <span class="arrow down"></span></button> <button type="button" aria-label="传送门" class="mobile-dropdown-title"><span class="title">传送门</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>
          在线编辑
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="https://tinypng.com/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  图片压缩
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></li><li class="dropdown-item"><h4>
          在线服务
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="https://www.aliyun.com/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  阿里云
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-subitem"><a href="https://cloud.tencent.com/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  腾讯云
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></li><li class="dropdown-item"><h4>
          博客指南
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="https://juejin.im/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  掘金
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-subitem"><a href="https://blog.csdn.net/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  CSDN
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></li></ul></div></div><div class="nav-item"><a href="/guide/notes/about.html" class="nav-link">
  关于
</a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">
  首页
</a></div><div class="nav-item"><a href="/studybook/lc/lc1.html" class="nav-link">
  学习笔记
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="传送门" class="dropdown-title"><span class="title">传送门</span> <span class="arrow down"></span></button> <button type="button" aria-label="传送门" class="mobile-dropdown-title"><span class="title">传送门</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>
          在线编辑
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="https://tinypng.com/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  图片压缩
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></li><li class="dropdown-item"><h4>
          在线服务
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="https://www.aliyun.com/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  阿里云
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-subitem"><a href="https://cloud.tencent.com/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  腾讯云
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></li><li class="dropdown-item"><h4>
          博客指南
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="https://juejin.im/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  掘金
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-subitem"><a href="https://blog.csdn.net/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  CSDN
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></li></ul></div></div><div class="nav-item"><a href="/guide/notes/about.html" class="nav-link">
  关于
</a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>LeetCode刷题</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>python基础</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading open"><span>动手学深度学习_代码总结</span> <span class="arrow down"></span></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/studybook/Dive-into-DL/d2lzh_pytorch.html" class="sidebar-link">d2lzh_pytorch</a></li><li><a href="/studybook/Dive-into-DL/第三章.html" class="active sidebar-link">第三章</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/studybook/Dive-into-DL/第三章.html#_3-2-线性回归的从零开始实现" class="sidebar-link">3.2 线性回归的从零开始实现</a></li><li class="sidebar-sub-header"><a href="/studybook/Dive-into-DL/第三章.html#_3-3-线性回归的简洁实现" class="sidebar-link">3.3 线性回归的简洁实现</a></li><li class="sidebar-sub-header"><a href="/studybook/Dive-into-DL/第三章.html#_3-5-图像分类数据集-fashion-mnist" class="sidebar-link">3.5 图像分类数据集(Fashion-MNIST)</a></li><li class="sidebar-sub-header"><a href="/studybook/Dive-into-DL/第三章.html#_3-6-softmax回归的从零开始实现" class="sidebar-link">3.6 softmax回归的从零开始实现</a></li><li class="sidebar-sub-header"><a href="/studybook/Dive-into-DL/第三章.html#_3-7-softmax回归的简洁实现" class="sidebar-link">3.7 softmax回归的简洁实现</a></li><li class="sidebar-sub-header"><a href="/studybook/Dive-into-DL/第三章.html#_3-8-多层感知机" class="sidebar-link">3.8 多层感知机</a></li><li class="sidebar-sub-header"><a href="/studybook/Dive-into-DL/第三章.html#_3-9-多层感知机的从零开始实现" class="sidebar-link">3.9 多层感知机的从零开始实现</a></li><li class="sidebar-sub-header"><a href="/studybook/Dive-into-DL/第三章.html#_3-10-多层感知机的简洁实现" class="sidebar-link">3.10 多层感知机的简洁实现</a></li><li class="sidebar-sub-header"><a href="/studybook/Dive-into-DL/第三章.html#_3-11-模型选择、欠拟合和过拟合" class="sidebar-link">3.11 模型选择、欠拟合和过拟合</a></li><li class="sidebar-sub-header"><a href="/studybook/Dive-into-DL/第三章.html#_3-12-权重衰减" class="sidebar-link">3.12 权重衰减</a></li><li class="sidebar-sub-header"><a href="/studybook/Dive-into-DL/第三章.html#_3-13-丢弃法" class="sidebar-link">3.13 丢弃法</a></li><li class="sidebar-sub-header"><a href="/studybook/Dive-into-DL/第三章.html#_3-16-实战kaggle比赛-房价预测" class="sidebar-link">3.16 实战Kaggle比赛：房价预测</a></li></ul></li><li><a href="/studybook/Dive-into-DL/第四章.html" class="sidebar-link">第四章</a></li></ul></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Machine Learning with Graphs</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>前端学习笔记</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>学习总结</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>其他</span> <span class="arrow right"></span></p> <!----></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="第三章"><a href="#第三章" class="header-anchor">#</a> 第三章</h1> <h2 id="_3-2-线性回归的从零开始实现"><a href="#_3-2-线性回归的从零开始实现" class="header-anchor">#</a> 3.2 线性回归的从零开始实现</h2> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> random
<span class="token keyword">from</span> re <span class="token keyword">import</span> L
<span class="token keyword">import</span> sys

<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> torch
<span class="token keyword">from</span> IPython <span class="token keyword">import</span> display
<span class="token keyword">from</span> IPython<span class="token punctuation">.</span>core<span class="token punctuation">.</span>display <span class="token keyword">import</span> set_matplotlib_formats

sys<span class="token punctuation">.</span>path<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">&quot;..&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">from</span> d2lzh_pytorch <span class="token keyword">import</span> <span class="token operator">*</span>

<span class="token comment"># 生成数据集</span>
num_inputs <span class="token operator">=</span> <span class="token number">2</span>
num_examples <span class="token operator">=</span> <span class="token number">1000</span>
true_w <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">3.4</span><span class="token punctuation">]</span>
true_b <span class="token operator">=</span> <span class="token number">4.2</span>
features <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>num_examples<span class="token punctuation">,</span> num_inputs<span class="token punctuation">,</span>
                       dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
labels <span class="token operator">=</span> true_w<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> features<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> true_w<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">*</span> features<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+</span> true_b
labels <span class="token operator">+=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.01</span><span class="token punctuation">,</span> size<span class="token operator">=</span>labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                       dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>

<span class="token comment"># print(features[0], labels[0])</span>

<span class="token comment"># set_figsize()</span>
<span class="token comment"># plt.scatter(features[:,1].numpy(),labels.numpy(),1)</span>

<span class="token comment"># 读取数据</span>
<span class="token keyword">def</span> <span class="token function">data_iter</span> <span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span>features<span class="token punctuation">,</span>labels<span class="token punctuation">)</span><span class="token punctuation">:</span>
    num_examples <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>features<span class="token punctuation">)</span>
    indices <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span>num_examples<span class="token punctuation">)</span><span class="token punctuation">)</span>
    random<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>indices<span class="token punctuation">)</span>  <span class="token comment"># random.shuffle()函数可以随机打乱数组顺序</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span>num_examples<span class="token punctuation">,</span>batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
        j <span class="token operator">=</span> torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span>indices<span class="token punctuation">[</span>i<span class="token punctuation">:</span><span class="token builtin">min</span><span class="token punctuation">(</span>i<span class="token operator">+</span>batch_size<span class="token punctuation">,</span>num_examples<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token comment"># yield 首先作用理解为return，它也可以返回一个或多个值,要想调用返回值就必须在循环中</span>
        <span class="token comment"># index_select() 中第一个参数 0 表示以行为标准选择</span>
        <span class="token keyword">yield</span> features<span class="token punctuation">.</span>index_select<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span>j<span class="token punctuation">)</span><span class="token punctuation">,</span>labels<span class="token punctuation">.</span>index_select<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span>j<span class="token punctuation">)</span> 

batch_size <span class="token operator">=</span> <span class="token number">10</span>
<span class="token comment"># for X,y in data_iter(batch_size,features,labels):</span>
<span class="token comment">#     print(X,y)</span>
<span class="token comment">#     break</span>

<span class="token comment"># 初始化模型参数</span>
w <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0.01</span><span class="token punctuation">,</span><span class="token punctuation">(</span>num_inputs<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
b <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
w<span class="token punctuation">.</span>requires_grad_<span class="token punctuation">(</span>requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
b<span class="token punctuation">.</span>requires_grad_<span class="token punctuation">(</span>requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment"># 定义模型</span>
<span class="token keyword">def</span> <span class="token function">linreg</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span>w<span class="token punctuation">,</span>b<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> torch<span class="token punctuation">.</span>mm<span class="token punctuation">(</span>X<span class="token punctuation">,</span>w<span class="token punctuation">)</span><span class="token operator">+</span>b

<span class="token comment"># 定义损失函数</span>
<span class="token keyword">def</span> <span class="token function">squared_loss</span><span class="token punctuation">(</span>y_hat<span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token punctuation">(</span>y_hat<span class="token operator">-</span>y<span class="token punctuation">.</span>view<span class="token punctuation">(</span>y_hat<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">**</span><span class="token number">2</span><span class="token operator">/</span><span class="token number">2</span>

<span class="token comment"># 定义优化算法</span>
<span class="token keyword">def</span> <span class="token function">sgd</span><span class="token punctuation">(</span>params<span class="token punctuation">,</span>lr<span class="token punctuation">,</span>batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> param <span class="token keyword">in</span> params<span class="token punctuation">:</span>
        param<span class="token punctuation">.</span>data <span class="token operator">-=</span> lr<span class="token operator">*</span>param<span class="token punctuation">.</span>grad<span class="token operator">/</span>batch_size

<span class="token comment"># 训练模型</span>
lr <span class="token operator">=</span> <span class="token number">0.03</span>
num_epochs <span class="token operator">=</span> <span class="token number">3</span>
net <span class="token operator">=</span> linreg
loss <span class="token operator">=</span> squared_loss

<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> X<span class="token punctuation">,</span>y <span class="token keyword">in</span> data_iter<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span>features<span class="token punctuation">,</span>labels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        l <span class="token operator">=</span> loss<span class="token punctuation">(</span>net<span class="token punctuation">(</span>X<span class="token punctuation">,</span>w<span class="token punctuation">,</span>b<span class="token punctuation">)</span><span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
        l<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        sgd<span class="token punctuation">(</span><span class="token punctuation">[</span>w<span class="token punctuation">,</span>b<span class="token punctuation">]</span><span class="token punctuation">,</span>lr<span class="token punctuation">,</span>batch_size<span class="token punctuation">)</span>

        w<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>data<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>
        b<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>data<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>
    
    train_l <span class="token operator">=</span> loss<span class="token punctuation">(</span>net<span class="token punctuation">(</span>features<span class="token punctuation">,</span>w<span class="token punctuation">,</span>b<span class="token punctuation">)</span><span class="token punctuation">,</span>labels<span class="token punctuation">)</span>
    <span class="token comment"># item()返回的是一个浮点型数据，所以我们在求loss或者accuracy时，一般使用item()</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'epoch %d, loss %f'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span>train_l<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> 

<span class="token keyword">print</span><span class="token punctuation">(</span>true_w<span class="token punctuation">,</span><span class="token string">'\n'</span><span class="token punctuation">,</span>w<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>true_b<span class="token punctuation">,</span><span class="token string">'\n'</span><span class="token punctuation">,</span>b<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br><span class="line-number">53</span><br><span class="line-number">54</span><br><span class="line-number">55</span><br><span class="line-number">56</span><br><span class="line-number">57</span><br><span class="line-number">58</span><br><span class="line-number">59</span><br><span class="line-number">60</span><br><span class="line-number">61</span><br><span class="line-number">62</span><br><span class="line-number">63</span><br><span class="line-number">64</span><br><span class="line-number">65</span><br><span class="line-number">66</span><br><span class="line-number">67</span><br><span class="line-number">68</span><br><span class="line-number">69</span><br><span class="line-number">70</span><br><span class="line-number">71</span><br><span class="line-number">72</span><br><span class="line-number">73</span><br><span class="line-number">74</span><br><span class="line-number">75</span><br><span class="line-number">76</span><br><span class="line-number">77</span><br><span class="line-number">78</span><br><span class="line-number">79</span><br><span class="line-number">80</span><br><span class="line-number">81</span><br><span class="line-number">82</span><br><span class="line-number">83</span><br><span class="line-number">84</span><br><span class="line-number">85</span><br></div></div><h2 id="_3-3-线性回归的简洁实现"><a href="#_3-3-线性回归的简洁实现" class="header-anchor">#</a> 3.3 线性回归的简洁实现</h2> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token comment"># 生成数据集</span>
num_inputs <span class="token operator">=</span> <span class="token number">2</span>
num_examples <span class="token operator">=</span> <span class="token number">1000</span>
true_w <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">3.4</span><span class="token punctuation">]</span>
true_b <span class="token operator">=</span> <span class="token number">4.2</span>

features <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>num_examples<span class="token punctuation">,</span>num_inputs<span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
labels <span class="token operator">=</span> true_w<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">*</span>features<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">+</span>true_w<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">*</span>features<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">+</span>true_b
labels <span class="token operator">+=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0.01</span><span class="token punctuation">,</span>size<span class="token operator">=</span>labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>

<span class="token comment"># 读取数据</span>
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">as</span> Data
batch_size <span class="token operator">=</span> <span class="token number">10</span>
dataset <span class="token operator">=</span> Data<span class="token punctuation">.</span>TensorDataset<span class="token punctuation">(</span>features<span class="token punctuation">,</span>labels<span class="token punctuation">)</span>
data_iter <span class="token operator">=</span> Data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span>batch_size<span class="token punctuation">,</span>shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment"># for X,y in data_iter:</span>
<span class="token comment">#     print(X,y)</span>
<span class="token comment">#     break</span>

<span class="token comment"># 定义模型</span>
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">class</span> <span class="token class-name">LinearNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>n_features<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>LinearNet<span class="token punctuation">,</span>self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>n_features<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>x<span class="token punctuation">)</span>

net <span class="token operator">=</span> LinearNet<span class="token punctuation">(</span>num_inputs<span class="token punctuation">)</span>

<span class="token comment"># print(net)</span>

<span class="token comment"># 1</span>
<span class="token comment"># net = nn.Sequential(</span>
<span class="token comment">#     nn.Linear(num_inputs,1)</span>
<span class="token comment"># )</span>
<span class="token comment"># 2</span>
<span class="token comment"># net = nn.Sequential()</span>
<span class="token comment"># net.add_module('linear',nn.Linear(num_inputs,1))</span>
<span class="token comment"># 3</span>
<span class="token comment"># from collections import OrderedDict</span>
<span class="token comment"># net = nn.Sequential(OrderedDict([</span>
<span class="token comment">#     ('linear',nn.Linear(num_inputs,1))</span>
<span class="token comment"># ]))</span>
<span class="token comment"># print(net)</span>
<span class="token comment"># print(net[0])</span>

<span class="token comment"># for param in net.parameters():</span>
<span class="token comment">#     print(param)</span>

<span class="token comment"># 初始化模型参数</span>
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> init
init<span class="token punctuation">.</span>normal_<span class="token punctuation">(</span>net<span class="token punctuation">.</span>linear<span class="token punctuation">.</span>weight<span class="token punctuation">,</span>mean<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>std<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>
init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>net<span class="token punctuation">.</span>linear<span class="token punctuation">.</span>bias<span class="token punctuation">,</span>val<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

<span class="token comment"># 定义损失函数  均方误差损失</span>
loss <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 定义优化算法</span>
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim
optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr<span class="token operator">=</span><span class="token number">0.03</span><span class="token punctuation">)</span>
<span class="token comment"># print(optimizer)</span>
<span class="token comment"># for param_group in optimizer.param_groups:</span>
<span class="token comment">#     param_group['lr'] *= 0.1</span>

<span class="token comment"># 训练模型</span>
num_epochs <span class="token operator">=</span> <span class="token number">3</span>
<span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>num_epochs<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> X<span class="token punctuation">,</span>y <span class="token keyword">in</span> data_iter<span class="token punctuation">:</span>
        output <span class="token operator">=</span>net<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
        l <span class="token operator">=</span> loss<span class="token punctuation">(</span>output<span class="token punctuation">,</span>y<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        l<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>      <span class="token comment"># l.backward()就是用来执行求解梯度的过程</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># optimizer.step()则是用来执行梯度下降进行权重参数更新的过程</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'epoch: %d, loss: %f'</span><span class="token operator">%</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span>l<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>true_w<span class="token punctuation">,</span>net<span class="token punctuation">.</span>linear<span class="token punctuation">.</span>weight<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>true_b<span class="token punctuation">,</span>net<span class="token punctuation">.</span>linear<span class="token punctuation">.</span>bias<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br><span class="line-number">53</span><br><span class="line-number">54</span><br><span class="line-number">55</span><br><span class="line-number">56</span><br><span class="line-number">57</span><br><span class="line-number">58</span><br><span class="line-number">59</span><br><span class="line-number">60</span><br><span class="line-number">61</span><br><span class="line-number">62</span><br><span class="line-number">63</span><br><span class="line-number">64</span><br><span class="line-number">65</span><br><span class="line-number">66</span><br><span class="line-number">67</span><br><span class="line-number">68</span><br><span class="line-number">69</span><br><span class="line-number">70</span><br><span class="line-number">71</span><br><span class="line-number">72</span><br><span class="line-number">73</span><br><span class="line-number">74</span><br><span class="line-number">75</span><br><span class="line-number">76</span><br><span class="line-number">77</span><br><span class="line-number">78</span><br><span class="line-number">79</span><br><span class="line-number">80</span><br><span class="line-number">81</span><br></div></div><h2 id="_3-5-图像分类数据集-fashion-mnist"><a href="#_3-5-图像分类数据集-fashion-mnist" class="header-anchor">#</a> 3.5 图像分类数据集(Fashion-MNIST)</h2> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token comment"># 获取数据集</span>
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torchvision
<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> transforms
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> time
<span class="token keyword">import</span> sys
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">as</span> Data
<span class="token keyword">from</span> torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>autoaugment <span class="token keyword">import</span> TrivialAugmentWide
sys<span class="token punctuation">.</span>path<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">&quot;..&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">import</span> d2lzh_pytorch <span class="token keyword">as</span> d2l

mnist_train <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>FashionMNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'~/Datasets/FashionMNIST'</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
mnist_test <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>FashionMNIST<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">'~/Datasets/FashionMNIST'</span><span class="token punctuation">,</span>train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>transform<span class="token operator">=</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># print(type(mnist_train))</span>
<span class="token comment"># print(len(mnist_train),len(mnist_test))</span>

<span class="token comment"># feature,label = mnist_train[0]</span>
<span class="token comment"># print(feature.shape,label)  # Channel x Height x Width</span>

<span class="token comment"># 将数值标签转成相应的文本标签</span>
<span class="token keyword">def</span> <span class="token function">get_fashion_mnist_labels</span><span class="token punctuation">(</span>labels<span class="token punctuation">)</span><span class="token punctuation">:</span>
    text_labels <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'t-shirt'</span><span class="token punctuation">,</span> <span class="token string">'trouser'</span><span class="token punctuation">,</span> <span class="token string">'pullover'</span><span class="token punctuation">,</span> <span class="token string">'dress'</span><span class="token punctuation">,</span> <span class="token string">'coat'</span><span class="token punctuation">,</span>
                   <span class="token string">'sandal'</span><span class="token punctuation">,</span> <span class="token string">'shirt'</span><span class="token punctuation">,</span> <span class="token string">'sneaker'</span><span class="token punctuation">,</span> <span class="token string">'bag'</span><span class="token punctuation">,</span> <span class="token string">'ankle boot'</span><span class="token punctuation">]</span>
    <span class="token keyword">return</span> <span class="token punctuation">[</span>text_labels<span class="token punctuation">[</span><span class="token builtin">int</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> labels<span class="token punctuation">]</span>

<span class="token comment"># 在一行里画出多张图像和对应标签</span>
<span class="token keyword">def</span> <span class="token function">show_fashion_mnist</span><span class="token punctuation">(</span>images<span class="token punctuation">,</span>labels<span class="token punctuation">)</span><span class="token punctuation">:</span>
    d2l<span class="token punctuation">.</span>use_svg_display<span class="token punctuation">(</span><span class="token punctuation">)</span>
    _<span class="token punctuation">,</span> figs <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>images<span class="token punctuation">)</span><span class="token punctuation">,</span> figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span> <span class="token number">12</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> f<span class="token punctuation">,</span>img<span class="token punctuation">,</span>lbl <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>figs<span class="token punctuation">,</span>images<span class="token punctuation">,</span>labels<span class="token punctuation">)</span><span class="token punctuation">:</span>
        f<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token number">28</span><span class="token punctuation">,</span><span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># imshow()函数用于将数据显示为图像</span>
        f<span class="token punctuation">.</span>set_title<span class="token punctuation">(</span>lbl<span class="token punctuation">)</span>  <span class="token comment"># 图片标题</span>
        f<span class="token punctuation">.</span>axes<span class="token punctuation">.</span>get_xaxis<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>set_visible<span class="token punctuation">(</span><span class="token boolean">False</span><span class="token punctuation">)</span>  <span class="token comment"># 隐藏坐标轴x</span>
        f<span class="token punctuation">.</span>axes<span class="token punctuation">.</span>get_yaxis<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>set_visible<span class="token punctuation">(</span><span class="token boolean">False</span><span class="token punctuation">)</span>  <span class="token comment"># 隐藏坐标轴y</span>
    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># X,y = [],[]</span>
<span class="token comment"># for i in range(10):</span>
<span class="token comment">#     X.append(mnist_train[i][0])</span>
<span class="token comment">#     y.append(mnist_train[i][1])</span>
<span class="token comment"># show_fashion_mnist(X,get_fashion_mnist_labels(y))</span>

<span class="token comment"># 读取小批量</span>
batch_size <span class="token operator">=</span> <span class="token number">256</span>
<span class="token keyword">if</span> sys<span class="token punctuation">.</span>platform<span class="token punctuation">.</span>startswith<span class="token punctuation">(</span><span class="token string">'win'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    num_workers <span class="token operator">=</span> <span class="token number">0</span>
<span class="token keyword">else</span><span class="token punctuation">:</span>
    num_workers <span class="token operator">=</span> <span class="token number">4</span>
train_iter <span class="token operator">=</span> Data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>mnist_train<span class="token punctuation">,</span>batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span>shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>num_workers<span class="token operator">=</span>num_workers<span class="token punctuation">)</span>
test_iter <span class="token operator">=</span> Data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>mnist_test<span class="token punctuation">,</span>batch_size<span class="token operator">=</span>batch_size<span class="token punctuation">,</span>shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span>num_workers<span class="token operator">=</span>num_workers<span class="token punctuation">)</span>

<span class="token comment"># 查看读取一遍训练数据需要的时间</span>
start <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> X<span class="token punctuation">,</span>y <span class="token keyword">in</span> train_iter<span class="token punctuation">:</span>
    <span class="token keyword">continue</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'%.2f sec'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">-</span>start<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br><span class="line-number">53</span><br><span class="line-number">54</span><br><span class="line-number">55</span><br><span class="line-number">56</span><br><span class="line-number">57</span><br><span class="line-number">58</span><br></div></div><h2 id="_3-6-softmax回归的从零开始实现"><a href="#_3-6-softmax回归的从零开始实现" class="header-anchor">#</a> 3.6 softmax回归的从零开始实现</h2> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">from</span> os <span class="token keyword">import</span> X_OK
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torchvision
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> sys
sys<span class="token punctuation">.</span>path<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">&quot;..&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">import</span> d2lzh_pytorch <span class="token keyword">as</span> d2l

<span class="token comment"># 获取和读取数据</span>
batch_size <span class="token operator">=</span> <span class="token number">256</span>
train_iter<span class="token punctuation">,</span>test_iter <span class="token operator">=</span> d2l<span class="token punctuation">.</span>load_data_fashion_mnist<span class="token punctuation">(</span>batch_size<span class="token punctuation">)</span>

<span class="token comment"># 初始化模型参数</span>
num_inputs <span class="token operator">=</span> <span class="token number">784</span>
num_outputs <span class="token operator">=</span> <span class="token number">10</span>
W <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0.01</span><span class="token punctuation">,</span><span class="token punctuation">(</span>num_inputs<span class="token punctuation">,</span>num_outputs<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span>
b <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>num_outputs<span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span>
W<span class="token punctuation">.</span>requires_grad_<span class="token punctuation">(</span>requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
b<span class="token punctuation">.</span>requires_grad_<span class="token punctuation">(</span>requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment"># 实现softmax运算</span>
<span class="token comment"># X = torch.tensor([[1,2,3],[4,5,6]])</span>
<span class="token comment"># print(X.sum(dim=0,keepdim=True))</span>
<span class="token comment"># print(X.sum(dim=1,keepdim=True))</span>
<span class="token keyword">def</span> <span class="token function">softmax</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">:</span>
    X_exp <span class="token operator">=</span> X<span class="token punctuation">.</span>exp<span class="token punctuation">(</span><span class="token punctuation">)</span>
    partition <span class="token operator">=</span> X_exp<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>keepdim<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> X_exp<span class="token operator">/</span>partition
<span class="token comment"># X = torch.rand((2,5))</span>
<span class="token comment"># X_prob = softmax(X)</span>
<span class="token comment"># print(X_prob,X_prob.sum(dim=1))</span>

<span class="token comment"># 定义模型</span>
<span class="token keyword">def</span> <span class="token function">net</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> softmax<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>mm<span class="token punctuation">(</span>X<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>num_inputs<span class="token punctuation">)</span><span class="token punctuation">,</span>W<span class="token punctuation">)</span><span class="token operator">+</span>b<span class="token punctuation">)</span>

<span class="token comment"># 定义损失函数  交叉熵</span>
<span class="token comment"># y_hat = torch.tensor([[0.1,0.3,0.6],[0.3,0.2,0.5]])</span>
<span class="token comment"># y = torch.LongTensor([0,2])</span>
<span class="token comment"># y_hat.gather(1,y.view(-1,1))</span>
<span class="token keyword">def</span> <span class="token function">cross_entropy</span><span class="token punctuation">(</span>y_hat<span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token operator">-</span>torch<span class="token punctuation">.</span>log<span class="token punctuation">(</span>y_hat<span class="token punctuation">.</span>gather<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>y<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 计算分类准确率</span>
<span class="token comment"># def accuracy(y_hat,y):</span>
<span class="token comment">#     return (y_hat.argmax(dim=1)==y).float().mean().item()</span>
<span class="token comment"># print(accuracy(y_hat,y))</span>
<span class="token comment"># 评价模型net在数据集data_iter上的准确率</span>
<span class="token keyword">def</span> <span class="token function">evaluate_accuracy</span><span class="token punctuation">(</span>data_iter<span class="token punctuation">,</span>net<span class="token punctuation">)</span><span class="token punctuation">:</span>
    acc_sum<span class="token punctuation">,</span>n<span class="token punctuation">,</span><span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">,</span><span class="token number">0</span>
    <span class="token keyword">for</span> X<span class="token punctuation">,</span>y <span class="token keyword">in</span> data_iter<span class="token punctuation">:</span>
        acc_sum <span class="token operator">+=</span> <span class="token punctuation">(</span>net<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">==</span>y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        n <span class="token operator">+=</span> y<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    <span class="token keyword">return</span> acc_sum<span class="token operator">/</span>n
<span class="token comment"># print(evaluate_accuracy(test_iter,net))</span>

<span class="token comment"># 训练模型</span>
num_epochs<span class="token punctuation">,</span>lr <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">,</span><span class="token number">0.1</span>

<span class="token keyword">def</span> <span class="token function">train_ch3</span><span class="token punctuation">(</span>net<span class="token punctuation">,</span>train_iter<span class="token punctuation">,</span>test_iter<span class="token punctuation">,</span>loss<span class="token punctuation">,</span>num_epochs<span class="token punctuation">,</span>batch_size<span class="token punctuation">,</span>
                params<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>lr<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>optimizer<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        train_l_sum<span class="token punctuation">,</span>train_acc_sum<span class="token punctuation">,</span>n <span class="token operator">=</span> <span class="token number">0.0</span><span class="token punctuation">,</span><span class="token number">0.0</span><span class="token punctuation">,</span><span class="token number">0</span>
        <span class="token keyword">for</span> X<span class="token punctuation">,</span>y <span class="token keyword">in</span> train_iter<span class="token punctuation">:</span>
            y_hat <span class="token operator">=</span> net<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
            l <span class="token operator">=</span> loss<span class="token punctuation">(</span>y_hat<span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

            <span class="token comment">#梯度清零</span>
            <span class="token keyword">if</span> optimizer <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
                optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token keyword">elif</span> params <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span> <span class="token keyword">and</span> params<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>grad <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
                <span class="token keyword">for</span> param <span class="token keyword">in</span> params<span class="token punctuation">:</span>
                    param<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>data<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>
            
            l<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token keyword">if</span> optimizer <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
                d2l<span class="token punctuation">.</span>sgd<span class="token punctuation">(</span>params<span class="token punctuation">,</span>lr<span class="token punctuation">,</span>batch_size<span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

            train_l_sum <span class="token operator">+=</span> l<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
            train_acc_sum <span class="token operator">+=</span> <span class="token punctuation">(</span>y_hat<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">==</span>y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
            n <span class="token operator">+=</span> y<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
        test_acc <span class="token operator">=</span> evaluate_accuracy<span class="token punctuation">(</span>test_iter<span class="token punctuation">,</span>net<span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'epoch %d, loss %.4f, train acc %.3f, test acc %.3f'</span>
                <span class="token operator">%</span><span class="token punctuation">(</span>epoch<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span>train_l_sum<span class="token operator">/</span>n<span class="token punctuation">,</span>train_acc_sum<span class="token operator">/</span>n<span class="token punctuation">,</span>test_acc<span class="token punctuation">)</span><span class="token punctuation">)</span>
train_ch3<span class="token punctuation">(</span>net<span class="token punctuation">,</span>train_iter<span class="token punctuation">,</span>test_iter<span class="token punctuation">,</span>cross_entropy<span class="token punctuation">,</span>num_epochs<span class="token punctuation">,</span>batch_size<span class="token punctuation">,</span><span class="token punctuation">[</span>W<span class="token punctuation">,</span>b<span class="token punctuation">]</span><span class="token punctuation">,</span>lr<span class="token punctuation">)</span>         

<span class="token comment"># 预测</span>
X<span class="token punctuation">,</span>y <span class="token operator">=</span> <span class="token builtin">iter</span><span class="token punctuation">(</span>test_iter<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span>

true_labels <span class="token operator">=</span> d2l<span class="token punctuation">.</span>get_fashion_mnist_labels<span class="token punctuation">(</span>y<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
pred_labels <span class="token operator">=</span> d2l<span class="token punctuation">.</span>get_fashion_mnist_labels<span class="token punctuation">(</span>net<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
titles <span class="token operator">=</span> <span class="token punctuation">[</span>true<span class="token operator">+</span><span class="token string">'\n'</span><span class="token operator">+</span>pred <span class="token keyword">for</span> true<span class="token punctuation">,</span>pred <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>true_labels<span class="token punctuation">,</span>pred_labels<span class="token punctuation">)</span><span class="token punctuation">]</span>

d2l<span class="token punctuation">.</span>show_fashion_mnist<span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">,</span>titles<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">9</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br><span class="line-number">53</span><br><span class="line-number">54</span><br><span class="line-number">55</span><br><span class="line-number">56</span><br><span class="line-number">57</span><br><span class="line-number">58</span><br><span class="line-number">59</span><br><span class="line-number">60</span><br><span class="line-number">61</span><br><span class="line-number">62</span><br><span class="line-number">63</span><br><span class="line-number">64</span><br><span class="line-number">65</span><br><span class="line-number">66</span><br><span class="line-number">67</span><br><span class="line-number">68</span><br><span class="line-number">69</span><br><span class="line-number">70</span><br><span class="line-number">71</span><br><span class="line-number">72</span><br><span class="line-number">73</span><br><span class="line-number">74</span><br><span class="line-number">75</span><br><span class="line-number">76</span><br><span class="line-number">77</span><br><span class="line-number">78</span><br><span class="line-number">79</span><br><span class="line-number">80</span><br><span class="line-number">81</span><br><span class="line-number">82</span><br><span class="line-number">83</span><br><span class="line-number">84</span><br><span class="line-number">85</span><br><span class="line-number">86</span><br><span class="line-number">87</span><br><span class="line-number">88</span><br><span class="line-number">89</span><br><span class="line-number">90</span><br><span class="line-number">91</span><br><span class="line-number">92</span><br><span class="line-number">93</span><br><span class="line-number">94</span><br><span class="line-number">95</span><br><span class="line-number">96</span><br></div></div><h2 id="_3-7-softmax回归的简洁实现"><a href="#_3-7-softmax回归的简洁实现" class="header-anchor">#</a> 3.7 softmax回归的简洁实现</h2> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> init
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> sys

sys<span class="token punctuation">.</span>path<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">&quot;..&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">import</span> d2lzh_pytorch <span class="token keyword">as</span> d2l

<span class="token comment"># 获取和读取数据</span>
batch_size <span class="token operator">=</span> <span class="token number">256</span>
train_iter<span class="token punctuation">,</span>test_iter <span class="token operator">=</span> d2l<span class="token punctuation">.</span>load_data_fashion_mnist<span class="token punctuation">(</span>batch_size<span class="token punctuation">)</span>

<span class="token comment"># 定义和初始化模型</span>
num_inputs <span class="token operator">=</span> <span class="token number">784</span>
num_outputs <span class="token operator">=</span> <span class="token number">10</span>

<span class="token comment"># class LinearNet(nn.Module):</span>
<span class="token comment">#     def __init__(self,num_inputs,num_outouts):</span>
<span class="token comment">#         super(LinearNet,self).__init__()</span>
<span class="token comment">#         self.linear = nn.Linear(num_inputs,num_outouts)</span>
<span class="token comment">#     def forward(self,x):</span>
<span class="token comment">#         return self.linear(x.view(x.shape[0],-1))</span>

<span class="token comment"># 对x 形状转换</span>
<span class="token keyword">class</span> <span class="token class-name">FlattenLayer</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>FlattenLayer<span class="token punctuation">,</span>self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>

<span class="token keyword">from</span> collections <span class="token keyword">import</span> OrderedDict
net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
    OrderedDict<span class="token punctuation">(</span><span class="token punctuation">[</span>
        <span class="token punctuation">(</span><span class="token string">'flatten'</span><span class="token punctuation">,</span>FlattenLayer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token punctuation">(</span><span class="token string">'linear'</span><span class="token punctuation">,</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>num_inputs<span class="token punctuation">,</span>num_outputs<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token punctuation">)</span>

init<span class="token punctuation">.</span>normal_<span class="token punctuation">(</span>net<span class="token punctuation">.</span>linear<span class="token punctuation">.</span>weight<span class="token punctuation">,</span>mean<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>std<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>
init<span class="token punctuation">.</span>constant_<span class="token punctuation">(</span>net<span class="token punctuation">.</span>linear<span class="token punctuation">.</span>bias<span class="token punctuation">,</span>val<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

<span class="token comment"># softmax和交叉熵损失函数</span>
loss <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 包括softmax运算和交叉熵损失计算</span>

<span class="token comment"># 定义优化算法</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span>  <span class="token comment"># 学习率为0.1的小批量随机梯度下降</span>

<span class="token comment"># 训练模型</span>
num_epochs <span class="token operator">=</span> <span class="token number">5</span>
d2l<span class="token punctuation">.</span>train_ch3<span class="token punctuation">(</span>net<span class="token punctuation">,</span>train_iter<span class="token punctuation">,</span>test_iter<span class="token punctuation">,</span>loss<span class="token punctuation">,</span>num_epochs<span class="token punctuation">,</span>batch_size<span class="token punctuation">,</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token boolean">None</span><span class="token punctuation">,</span>optimizer<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br></div></div><h2 id="_3-8-多层感知机"><a href="#_3-8-多层感知机" class="header-anchor">#</a> 3.8 多层感知机</h2> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token comment"># 激活函数</span>
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pylab <span class="token keyword">as</span> plt
<span class="token keyword">import</span> sys
sys<span class="token punctuation">.</span>path<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">&quot;..&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">import</span> d2lzh_pytorch <span class="token keyword">as</span> d2l

<span class="token keyword">def</span> <span class="token function">xyplot</span><span class="token punctuation">(</span>x_vals<span class="token punctuation">,</span>y_vals<span class="token punctuation">,</span>name<span class="token punctuation">)</span><span class="token punctuation">:</span>
    d2l<span class="token punctuation">.</span>set_figsize<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">2.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    d2l<span class="token punctuation">.</span>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x_vals<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>y_vals<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    d2l<span class="token punctuation">.</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'x'</span><span class="token punctuation">)</span>
    d2l<span class="token punctuation">.</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span>name<span class="token operator">+</span><span class="token string">'(x)'</span><span class="token punctuation">)</span>

<span class="token comment"># ReLU函数</span>
x <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">8.0</span><span class="token punctuation">,</span><span class="token number">8.0</span><span class="token punctuation">,</span><span class="token number">0.1</span><span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> x<span class="token punctuation">.</span>relu<span class="token punctuation">(</span><span class="token punctuation">)</span>
xyplot<span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">,</span><span class="token string">'relu'</span><span class="token punctuation">)</span>
<span class="token comment"># ReLU函数导数</span>
y<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
xyplot<span class="token punctuation">(</span>x<span class="token punctuation">,</span>x<span class="token punctuation">.</span>grad<span class="token punctuation">,</span><span class="token string">'grad of relu'</span><span class="token punctuation">)</span>

<span class="token comment"># sigmoid函数</span>
y <span class="token operator">=</span> x<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>
xyplot<span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">,</span><span class="token string">'sigmoid'</span><span class="token punctuation">)</span>
<span class="token comment"># sigmoid函数导数</span>
x<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>
y<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
xyplot<span class="token punctuation">(</span>x<span class="token punctuation">,</span>x<span class="token punctuation">.</span>grad<span class="token punctuation">,</span><span class="token string">'grad of sigmoid'</span><span class="token punctuation">)</span>

<span class="token comment"># tanh函数</span>
y <span class="token operator">=</span> x<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span><span class="token punctuation">)</span>
xyplot<span class="token punctuation">(</span>x<span class="token punctuation">,</span>y<span class="token punctuation">,</span><span class="token string">'tanh'</span><span class="token punctuation">)</span>
<span class="token comment"># tanh函数导数</span>
x<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>
y<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
xyplot<span class="token punctuation">(</span>x<span class="token punctuation">,</span>x<span class="token punctuation">.</span>grad<span class="token punctuation">,</span><span class="token string">'gard of tanh'</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br></div></div><h2 id="_3-9-多层感知机的从零开始实现"><a href="#_3-9-多层感知机的从零开始实现" class="header-anchor">#</a> 3.9 多层感知机的从零开始实现</h2> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> torch 
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> sys
sys<span class="token punctuation">.</span>path<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">&quot;..&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">import</span> d2lzh_pytorch <span class="token keyword">as</span> d2l

<span class="token comment"># 获取和读取数据</span>
batch_size <span class="token operator">=</span> <span class="token number">256</span>
train_iter<span class="token punctuation">,</span>test_iter <span class="token operator">=</span> d2l<span class="token punctuation">.</span>load_data_fashion_mnist<span class="token punctuation">(</span>batch_size<span class="token punctuation">)</span>

<span class="token comment"># 定义模型参数</span>
num_inputs<span class="token punctuation">,</span>num_outputs<span class="token punctuation">,</span>num_hiddens <span class="token operator">=</span> <span class="token number">784</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">256</span>
W1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0.01</span><span class="token punctuation">,</span><span class="token punctuation">(</span>num_inputs<span class="token punctuation">,</span>num_hiddens<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span>
b1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>num_hiddens<span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span>
W2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0.01</span><span class="token punctuation">,</span><span class="token punctuation">(</span>num_hiddens<span class="token punctuation">,</span>num_outputs<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span>
b2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>num_outputs<span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span>
params <span class="token operator">=</span> <span class="token punctuation">[</span>W1<span class="token punctuation">,</span>b1<span class="token punctuation">,</span>W2<span class="token punctuation">,</span>b2<span class="token punctuation">]</span>
<span class="token keyword">for</span> param <span class="token keyword">in</span> params<span class="token punctuation">:</span>
    param<span class="token punctuation">.</span>requires_grad_<span class="token punctuation">(</span>requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment"># 定义激活函数</span>
<span class="token keyword">def</span> <span class="token function">relu</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token builtin">input</span><span class="token operator">=</span>X<span class="token punctuation">,</span>other<span class="token operator">=</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 定义模型</span>
<span class="token keyword">def</span> <span class="token function">net</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">:</span>
    X <span class="token operator">=</span> X<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>num_inputs<span class="token punctuation">)</span><span class="token punctuation">)</span>
    H <span class="token operator">=</span> relu<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>mm<span class="token punctuation">(</span>X<span class="token punctuation">,</span>W1<span class="token punctuation">)</span><span class="token operator">+</span>b1<span class="token punctuation">)</span>
    <span class="token keyword">return</span> torch<span class="token punctuation">.</span>mm<span class="token punctuation">(</span>H<span class="token punctuation">,</span>W2<span class="token punctuation">)</span><span class="token operator">+</span>b2

<span class="token comment"># 定义损失函数</span>
loss <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 训练模型</span>
num_epochs<span class="token punctuation">,</span>lr <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">,</span><span class="token number">100.0</span>
d2l<span class="token punctuation">.</span>train_ch3<span class="token punctuation">(</span>net<span class="token punctuation">,</span>train_iter<span class="token punctuation">,</span>test_iter<span class="token punctuation">,</span>loss<span class="token punctuation">,</span>num_epochs<span class="token punctuation">,</span>batch_size<span class="token punctuation">,</span>params<span class="token punctuation">,</span>lr<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br></div></div><h2 id="_3-10-多层感知机的简洁实现"><a href="#_3-10-多层感知机的简洁实现" class="header-anchor">#</a> 3.10 多层感知机的简洁实现</h2> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">import</span> init
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> sys
sys<span class="token punctuation">.</span>path<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">&quot;..&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">import</span> d2lzh_pytorch <span class="token keyword">as</span> d2l

<span class="token comment"># 定义模型</span>
num_inputs<span class="token punctuation">,</span>num_outputs<span class="token punctuation">,</span>num_hiddens <span class="token operator">=</span> <span class="token number">784</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">256</span>

net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
    d2l<span class="token punctuation">.</span>FlattenLayer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>num_inputs<span class="token punctuation">,</span>num_hiddens<span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>num_hiddens<span class="token punctuation">,</span>num_outputs<span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
<span class="token keyword">for</span> param <span class="token keyword">in</span> net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    param<span class="token punctuation">.</span>requires_grad_<span class="token punctuation">(</span>requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token comment"># 读取数据并训练模型</span>
batch_size <span class="token operator">=</span> <span class="token number">256</span>
train_iter<span class="token punctuation">,</span>test_iter <span class="token operator">=</span> d2l<span class="token punctuation">.</span>load_data_fashion_mnist<span class="token punctuation">(</span>batch_size<span class="token punctuation">)</span>
loss <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span>
num_epochs <span class="token operator">=</span> <span class="token number">5</span>

d2l<span class="token punctuation">.</span>train_ch3<span class="token punctuation">(</span>net<span class="token punctuation">,</span>train_iter<span class="token punctuation">,</span>test_iter<span class="token punctuation">,</span>loss<span class="token punctuation">,</span>num_epochs<span class="token punctuation">,</span>batch_size<span class="token punctuation">,</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token boolean">None</span><span class="token punctuation">,</span>optimizer<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br></div></div><h2 id="_3-11-模型选择、欠拟合和过拟合"><a href="#_3-11-模型选择、欠拟合和过拟合" class="header-anchor">#</a> 3.11 模型选择、欠拟合和过拟合</h2> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> sys

sys<span class="token punctuation">.</span>path<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">&quot;..&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">import</span> d2lzh_pytorch <span class="token keyword">as</span> d2l

<span class="token comment"># 生成数据集</span>
n_train<span class="token punctuation">,</span>n_test<span class="token punctuation">,</span>true_w<span class="token punctuation">,</span>true_b <span class="token operator">=</span> <span class="token number">100</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">1.2</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">3.4</span><span class="token punctuation">,</span><span class="token number">5.6</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token number">5</span>
features <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>n_train<span class="token operator">+</span>n_test<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
poly_features <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>features<span class="token punctuation">,</span>torch<span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span>features<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>torch<span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span>features<span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
labels <span class="token operator">=</span> <span class="token punctuation">(</span>true_w<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">*</span>poly_features<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">+</span>true_w<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">*</span>poly_features<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">+</span>true_w<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token operator">*</span>poly_features<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token operator">+</span>true_b<span class="token punctuation">)</span>
labels <span class="token operator">+=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0.01</span><span class="token punctuation">,</span>size<span class="token operator">=</span>labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span>
<span class="token comment"># features[:2],poly_features[:2],labels[:2]</span>

<span class="token comment"># 定义、训练和测试模型</span>
<span class="token comment"># 作图函数semilogy</span>
<span class="token keyword">def</span> <span class="token function">semilogy</span><span class="token punctuation">(</span>x_vals<span class="token punctuation">,</span>y_vals<span class="token punctuation">,</span>x_label<span class="token punctuation">,</span>y_label<span class="token punctuation">,</span>x2_vals<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>y2_vals<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>legend<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3.5</span><span class="token punctuation">,</span><span class="token number">2.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    d2l<span class="token punctuation">.</span>set_figsize<span class="token punctuation">(</span>figsize<span class="token punctuation">)</span>
    d2l<span class="token punctuation">.</span>plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span>x_label<span class="token punctuation">)</span>
    d2l<span class="token punctuation">.</span>plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span>y_label<span class="token punctuation">)</span>
    d2l<span class="token punctuation">.</span>plt<span class="token punctuation">.</span>semilogy<span class="token punctuation">(</span>x_vals<span class="token punctuation">,</span>y_vals<span class="token punctuation">)</span>
    <span class="token keyword">if</span> x2_vals <span class="token keyword">and</span> y2_vals<span class="token punctuation">:</span>
        d2l<span class="token punctuation">.</span>plt<span class="token punctuation">.</span>semilogy<span class="token punctuation">(</span>x2_vals<span class="token punctuation">,</span>y2_vals<span class="token punctuation">,</span>linestyle<span class="token operator">=</span><span class="token string">':'</span><span class="token punctuation">)</span>
        d2l<span class="token punctuation">.</span>plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>legend<span class="token punctuation">)</span>

num_epochs<span class="token punctuation">,</span>loss <span class="token operator">=</span> <span class="token number">100</span><span class="token punctuation">,</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">def</span> <span class="token function">fit_and_plot</span><span class="token punctuation">(</span>train_features<span class="token punctuation">,</span>test_features<span class="token punctuation">,</span>train_labels<span class="token punctuation">,</span>test_labels<span class="token punctuation">)</span><span class="token punctuation">:</span>
    net <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>train_features<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>

    batch_size <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span>train_labels<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    dataset <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>TensorDataset<span class="token punctuation">(</span>train_features<span class="token punctuation">,</span>train_labels<span class="token punctuation">)</span>
    train_iter <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span>batch_size<span class="token punctuation">,</span>shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

    optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>
    train_ls<span class="token punctuation">,</span>test_ls <span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> X<span class="token punctuation">,</span>y <span class="token keyword">in</span> train_iter<span class="token punctuation">:</span>
            l <span class="token operator">=</span> loss<span class="token punctuation">(</span>net<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">,</span>y<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
            l<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
            optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        train_labels <span class="token operator">=</span> train_labels<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
        test_labels <span class="token operator">=</span> test_labels<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
        train_ls<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">(</span>net<span class="token punctuation">(</span>train_features<span class="token punctuation">)</span><span class="token punctuation">,</span>train_labels<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        test_ls<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">(</span>net<span class="token punctuation">(</span>test_features<span class="token punctuation">)</span><span class="token punctuation">,</span>test_labels<span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'final epoch:train loss'</span><span class="token punctuation">,</span>train_ls<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token string">'test loss'</span><span class="token punctuation">,</span>test_ls<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    semilogy<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>num_epochs<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>train_ls<span class="token punctuation">,</span><span class="token string">'epochs'</span><span class="token punctuation">,</span><span class="token string">'loss'</span><span class="token punctuation">,</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>num_epochs<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>test_ls<span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span><span class="token string">'test'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'weight:'</span><span class="token punctuation">,</span>net<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>data<span class="token punctuation">,</span>
            <span class="token string">'\nbias:'</span><span class="token punctuation">,</span>net<span class="token punctuation">.</span>bias<span class="token punctuation">.</span>data<span class="token punctuation">)</span>
<span class="token comment"># 三阶多项式函数拟合（正常）</span>
fit_and_plot<span class="token punctuation">(</span>poly_features<span class="token punctuation">[</span><span class="token punctuation">:</span>n_train<span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span>poly_features<span class="token punctuation">[</span>n_train<span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span>labels<span class="token punctuation">[</span><span class="token punctuation">:</span>n_train<span class="token punctuation">]</span><span class="token punctuation">,</span>labels<span class="token punctuation">[</span>n_train<span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 线性函数拟合（欠拟合）</span>
fit_and_plot<span class="token punctuation">(</span>features<span class="token punctuation">[</span><span class="token punctuation">:</span>n_train<span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span>features<span class="token punctuation">[</span>n_train<span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span>labels<span class="token punctuation">[</span><span class="token punctuation">:</span>n_train<span class="token punctuation">]</span><span class="token punctuation">,</span>labels<span class="token punctuation">[</span>n_train<span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 训练样本不足（过拟合）</span>
fit_and_plot<span class="token punctuation">(</span>poly_features<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span>poly_features<span class="token punctuation">[</span>n_train<span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span>labels<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>labels<span class="token punctuation">[</span>n_train<span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br><span class="line-number">53</span><br><span class="line-number">54</span><br><span class="line-number">55</span><br><span class="line-number">56</span><br><span class="line-number">57</span><br><span class="line-number">58</span><br></div></div><h2 id="_3-12-权重衰减"><a href="#_3-12-权重衰减" class="header-anchor">#</a> 3.12 权重衰减</h2> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> sys

<span class="token keyword">from</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">import</span> optimizer
sys<span class="token punctuation">.</span>path<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">&quot;..&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">import</span> d2lzh_pytorch <span class="token keyword">as</span> d2l

<span class="token comment"># 高维线性回归实验</span>
n_train<span class="token punctuation">,</span>n_test<span class="token punctuation">,</span>num_inputs <span class="token operator">=</span> <span class="token number">20</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">200</span>
true_w<span class="token punctuation">,</span>true_b <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span>num_inputs<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">0.01</span><span class="token punctuation">,</span><span class="token number">0.05</span>

features <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token punctuation">(</span>n_train<span class="token operator">+</span>n_test<span class="token punctuation">,</span>num_inputs<span class="token punctuation">)</span><span class="token punctuation">)</span>
labels <span class="token operator">=</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>features<span class="token punctuation">,</span>true_w<span class="token punctuation">)</span><span class="token operator">+</span>true_b
labels <span class="token operator">+=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0.01</span><span class="token punctuation">,</span>size<span class="token operator">=</span>labels<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span>
train_features<span class="token punctuation">,</span>test_features <span class="token operator">=</span> features<span class="token punctuation">[</span><span class="token punctuation">:</span>n_train<span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span>features<span class="token punctuation">[</span>n_train<span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
train_labels<span class="token punctuation">,</span>test_labels <span class="token operator">=</span> labels<span class="token punctuation">[</span><span class="token punctuation">:</span>n_train<span class="token punctuation">]</span><span class="token punctuation">,</span>labels<span class="token punctuation">[</span>n_train<span class="token punctuation">:</span><span class="token punctuation">]</span>

<span class="token comment"># 从零开始实现</span>
<span class="token comment"># 初始化模型参数</span>
<span class="token keyword">def</span> <span class="token function">init_params</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    w <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token punctuation">(</span>num_inputs<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    b <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> <span class="token punctuation">[</span>w<span class="token punctuation">,</span>b<span class="token punctuation">]</span>

<span class="token comment"># 定义L2范数惩罚项</span>
<span class="token keyword">def</span> <span class="token function">l2_penalty</span><span class="token punctuation">(</span>w<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token punctuation">(</span>w<span class="token operator">**</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">2</span>

<span class="token comment"># 定义训练和测试</span>
batch_size<span class="token punctuation">,</span>num_epochs<span class="token punctuation">,</span>lr <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">0.003</span>
net<span class="token punctuation">,</span>loss <span class="token operator">=</span> d2l<span class="token punctuation">.</span>linreg<span class="token punctuation">,</span>d2l<span class="token punctuation">.</span>squared_loss

dataset <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>TensorDataset<span class="token punctuation">(</span>train_features<span class="token punctuation">,</span>train_labels<span class="token punctuation">)</span>
train_iter <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span>batch_size<span class="token punctuation">,</span>shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">fit_and_plot</span><span class="token punctuation">(</span>lambd<span class="token punctuation">)</span><span class="token punctuation">:</span>
    w<span class="token punctuation">,</span>b <span class="token operator">=</span> init_params<span class="token punctuation">(</span><span class="token punctuation">)</span>
    train_ls<span class="token punctuation">,</span>test_ls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> X<span class="token punctuation">,</span>y <span class="token keyword">in</span> train_iter<span class="token punctuation">:</span>
            l <span class="token operator">=</span> loss<span class="token punctuation">(</span>net<span class="token punctuation">(</span>X<span class="token punctuation">,</span>w<span class="token punctuation">,</span>b<span class="token punctuation">)</span><span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token operator">+</span>lambd<span class="token operator">*</span>l2_penalty<span class="token punctuation">(</span>w<span class="token punctuation">)</span>
            l <span class="token operator">=</span> l<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
            
            <span class="token keyword">if</span> w<span class="token punctuation">.</span>grad <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
                w<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>data<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>
                b<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>data<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>

            l<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
            d2l<span class="token punctuation">.</span>sgd<span class="token punctuation">(</span><span class="token punctuation">[</span>w<span class="token punctuation">,</span>b<span class="token punctuation">]</span><span class="token punctuation">,</span>lr<span class="token punctuation">,</span>batch_size<span class="token punctuation">)</span>
        train_ls<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">(</span>net<span class="token punctuation">(</span>train_features<span class="token punctuation">,</span>w<span class="token punctuation">,</span>b<span class="token punctuation">)</span><span class="token punctuation">,</span>train_labels<span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        test_ls<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">(</span>net<span class="token punctuation">(</span>test_features<span class="token punctuation">,</span>w<span class="token punctuation">,</span>b<span class="token punctuation">)</span><span class="token punctuation">,</span>test_labels<span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    d2l<span class="token punctuation">.</span>semilogy<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>num_epochs<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>train_ls<span class="token punctuation">,</span><span class="token string">'epochs'</span><span class="token punctuation">,</span><span class="token string">'loss'</span><span class="token punctuation">,</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>num_epochs<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>test_ls<span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span><span class="token string">'test'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'L2 norm of w:'</span><span class="token punctuation">,</span>w<span class="token punctuation">.</span>norm<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 观察过拟合</span>
<span class="token comment"># fit_and_plot(lambd=0)</span>

<span class="token comment"># 使用权重衰减</span>
<span class="token comment"># fit_and_plot(lambd=3)</span>

<span class="token comment"># 简洁实现</span>
<span class="token keyword">def</span> <span class="token function">fit_and_plot_pytorch</span><span class="token punctuation">(</span>wd<span class="token punctuation">)</span><span class="token punctuation">:</span>
    net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>num_inputs<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
    nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>normal_<span class="token punctuation">(</span>net<span class="token punctuation">.</span>weight<span class="token punctuation">,</span>mean<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>std<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
    nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>normal_<span class="token punctuation">(</span>net<span class="token punctuation">.</span>bias<span class="token punctuation">,</span>mean<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>std<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
    optimizer_w <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>params<span class="token operator">=</span><span class="token punctuation">[</span>net<span class="token punctuation">.</span>weight<span class="token punctuation">]</span><span class="token punctuation">,</span>lr<span class="token operator">=</span>lr<span class="token punctuation">,</span>weight_decay<span class="token operator">=</span>wd<span class="token punctuation">)</span>
    optimizer_b <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>params<span class="token operator">=</span><span class="token punctuation">[</span>net<span class="token punctuation">.</span>bias<span class="token punctuation">]</span><span class="token punctuation">,</span>lr<span class="token operator">=</span>lr<span class="token punctuation">)</span>
    train_ls<span class="token punctuation">,</span>test_ls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> X<span class="token punctuation">,</span>y <span class="token keyword">in</span> train_iter<span class="token punctuation">:</span>
            l <span class="token operator">=</span> loss<span class="token punctuation">(</span>net<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span>
            optimizer_w<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
            optimizer_b<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
            l<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
            optimizer_w<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
            optimizer_b<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        train_ls<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">(</span>net<span class="token punctuation">(</span>train_features<span class="token punctuation">)</span><span class="token punctuation">,</span>train_labels<span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        test_ls<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">(</span>net<span class="token punctuation">(</span>test_features<span class="token punctuation">)</span><span class="token punctuation">,</span>test_labels<span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    d2l<span class="token punctuation">.</span>semilogy<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>num_epochs<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>train_ls<span class="token punctuation">,</span><span class="token string">'epochs'</span><span class="token punctuation">,</span><span class="token string">'loss'</span><span class="token punctuation">,</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>num_epochs<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>test_ls<span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span><span class="token string">'test'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'L2 norm of w:'</span><span class="token punctuation">,</span>net<span class="token punctuation">.</span>weight<span class="token punctuation">.</span>data<span class="token punctuation">.</span>norm<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># fit_and_plot_pytorch(0)</span>
fit_and_plot_pytorch<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br><span class="line-number">53</span><br><span class="line-number">54</span><br><span class="line-number">55</span><br><span class="line-number">56</span><br><span class="line-number">57</span><br><span class="line-number">58</span><br><span class="line-number">59</span><br><span class="line-number">60</span><br><span class="line-number">61</span><br><span class="line-number">62</span><br><span class="line-number">63</span><br><span class="line-number">64</span><br><span class="line-number">65</span><br><span class="line-number">66</span><br><span class="line-number">67</span><br><span class="line-number">68</span><br><span class="line-number">69</span><br><span class="line-number">70</span><br><span class="line-number">71</span><br><span class="line-number">72</span><br><span class="line-number">73</span><br><span class="line-number">74</span><br><span class="line-number">75</span><br><span class="line-number">76</span><br><span class="line-number">77</span><br><span class="line-number">78</span><br><span class="line-number">79</span><br><span class="line-number">80</span><br><span class="line-number">81</span><br><span class="line-number">82</span><br><span class="line-number">83</span><br><span class="line-number">84</span><br><span class="line-number">85</span><br></div></div><h2 id="_3-13-丢弃法"><a href="#_3-13-丢弃法" class="header-anchor">#</a> 3.13 丢弃法</h2> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token comment"># 从零开始实现</span>
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> sys
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>modules<span class="token punctuation">.</span>activation <span class="token keyword">import</span> ReLU

<span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>modules<span class="token punctuation">.</span>linear <span class="token keyword">import</span> Linear
sys<span class="token punctuation">.</span>path<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">&quot;..&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">import</span> d2lzh_pytorch <span class="token keyword">as</span> d2l

<span class="token comment"># 以drop_prob的概率丢弃X中的元素</span>
<span class="token keyword">def</span> <span class="token function">dropout</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span>drop_prob<span class="token punctuation">)</span><span class="token punctuation">:</span>
    X <span class="token operator">=</span> X<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">assert</span> <span class="token number">0</span> <span class="token operator">&lt;=</span> drop_prob <span class="token operator">&lt;=</span> <span class="token number">1</span>
    keep_prob <span class="token operator">=</span> <span class="token number">1</span><span class="token operator">-</span>drop_prob
    <span class="token keyword">if</span> keep_prob <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
    <span class="token comment"># drop_prob是丢弃的概率.其中我们用torch.rand(X.shape) &lt; keep_prob去生成一组bool数,表明要丢弃哪些,保留哪些.</span>
    mask <span class="token operator">=</span> <span class="token punctuation">(</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>X<span class="token punctuation">.</span>shape<span class="token punctuation">)</span> <span class="token operator">&lt;</span> keep_prob<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> mask<span class="token operator">*</span>X<span class="token operator">/</span>keep_prob

<span class="token comment"># X = torch.arange(16).view(2,8)</span>
<span class="token comment"># dropout(X,0)</span>
<span class="token comment"># dropout(X,0.5)</span>
<span class="token comment"># dropout(X,1)</span>

<span class="token comment"># 定义模型参数</span>
num_inputs<span class="token punctuation">,</span>num_outputs<span class="token punctuation">,</span>num_hidden1<span class="token punctuation">,</span>num_hidden2 <span class="token operator">=</span> <span class="token number">784</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">256</span><span class="token punctuation">,</span><span class="token number">256</span>
W1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0.01</span><span class="token punctuation">,</span>size<span class="token operator">=</span><span class="token punctuation">(</span>num_inputs<span class="token punctuation">,</span>num_hidden1<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
b1 <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>num_hidden1<span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
W2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0.01</span><span class="token punctuation">,</span>size<span class="token operator">=</span><span class="token punctuation">(</span>num_hidden1<span class="token punctuation">,</span>num_hidden2<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
b2 <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>num_hidden2<span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
W3 <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0.01</span><span class="token punctuation">,</span>size<span class="token operator">=</span><span class="token punctuation">(</span>num_hidden2<span class="token punctuation">,</span>num_outputs<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
b3 <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>num_outputs<span class="token punctuation">,</span>requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
params <span class="token operator">=</span> <span class="token punctuation">[</span>W1<span class="token punctuation">,</span>b1<span class="token punctuation">,</span>W2<span class="token punctuation">,</span>b2<span class="token punctuation">,</span>W3<span class="token punctuation">,</span>b3<span class="token punctuation">]</span>

<span class="token comment"># 定义模型</span>
drop_prob1<span class="token punctuation">,</span>drop_prob2 <span class="token operator">=</span> <span class="token number">0.2</span><span class="token punctuation">,</span><span class="token number">0.5</span>
<span class="token keyword">def</span> <span class="token function">net</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span>is_training<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    X <span class="token operator">=</span> X<span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>num_inputs<span class="token punctuation">)</span>
    H1 <span class="token operator">=</span> <span class="token punctuation">(</span>torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>X<span class="token punctuation">,</span>W1<span class="token punctuation">)</span><span class="token operator">+</span>b1<span class="token punctuation">)</span><span class="token punctuation">.</span>relu<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> is_training<span class="token punctuation">:</span>
        H1 <span class="token operator">=</span> dropout<span class="token punctuation">(</span>H1<span class="token punctuation">,</span>drop_prob1<span class="token punctuation">)</span>
    H2 <span class="token operator">=</span> <span class="token punctuation">(</span>torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>H1<span class="token punctuation">,</span>W2<span class="token punctuation">)</span><span class="token operator">+</span>b2<span class="token punctuation">)</span><span class="token punctuation">.</span>relu<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> is_training<span class="token punctuation">:</span>
        H2 <span class="token operator">=</span> dropout<span class="token punctuation">(</span>H2<span class="token punctuation">,</span>drop_prob2<span class="token punctuation">)</span>
    <span class="token keyword">return</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>H2<span class="token punctuation">,</span>W3<span class="token punctuation">)</span><span class="token operator">+</span>b3
<span class="token comment"># isinstance(object, classinfo) 如果object的类型与classinfo相同则返回 True，否则返回 False</span>

<span class="token comment"># 评价模型net在数据集data_iter上的准确率 </span>
<span class="token keyword">def</span> <span class="token function">evaluate_accuracy</span><span class="token punctuation">(</span>data_iter<span class="token punctuation">,</span>net<span class="token punctuation">)</span><span class="token punctuation">:</span>
    acc_sum<span class="token punctuation">,</span>n<span class="token punctuation">,</span><span class="token operator">=</span><span class="token number">0.0</span><span class="token punctuation">,</span><span class="token number">0</span>
    <span class="token keyword">for</span> X<span class="token punctuation">,</span>y <span class="token keyword">in</span> data_iter<span class="token punctuation">:</span>
        <span class="token keyword">if</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>net<span class="token punctuation">,</span>torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
            net<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 评估模式, 这会关闭dropout</span>
            acc_sum <span class="token operator">+=</span> <span class="token punctuation">(</span>net<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">==</span>y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
            net<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token comment"># .__code__.co_varnames 获取函数内部变量名称</span>
            <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token string">'is_training'</span> <span class="token keyword">in</span> net<span class="token punctuation">.</span>__code__<span class="token punctuation">.</span>co_varnames<span class="token punctuation">)</span><span class="token punctuation">:</span>
                acc_sum <span class="token operator">+=</span> <span class="token punctuation">(</span>net<span class="token punctuation">(</span>X<span class="token punctuation">,</span>is_training<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span><span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">==</span>y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token keyword">else</span><span class="token punctuation">:</span>
                acc_sum <span class="token operator">+=</span> <span class="token punctuation">(</span>net<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">==</span>y<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
        n <span class="token operator">+=</span> y<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    <span class="token keyword">return</span> acc_sum<span class="token operator">/</span>n

<span class="token comment"># 训练和测试模型</span>
num_epochs<span class="token punctuation">,</span>lr<span class="token punctuation">,</span>batch_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">,</span><span class="token number">100.0</span><span class="token punctuation">,</span><span class="token number">256</span>
loss <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
train_iter<span class="token punctuation">,</span>test_iter <span class="token operator">=</span> d2l<span class="token punctuation">.</span>load_data_fashion_mnist<span class="token punctuation">(</span>batch_size<span class="token punctuation">)</span>
<span class="token comment"># d2l.train_ch3(net,train_iter,test_iter,loss,num_epochs,batch_size,params,lr)</span>

<span class="token comment"># 简洁实现</span>
net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
    d2l<span class="token punctuation">.</span>FlattenLayer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>num_inputs<span class="token punctuation">,</span>num_hidden1<span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>drop_prob1<span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>num_hidden1<span class="token punctuation">,</span>num_hidden2<span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>Dropout<span class="token punctuation">(</span>drop_prob2<span class="token punctuation">)</span><span class="token punctuation">,</span>
    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>num_hidden2<span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">)</span>
    <span class="token punctuation">)</span>

<span class="token keyword">for</span> param <span class="token keyword">in</span> net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>normal_<span class="token punctuation">(</span>param<span class="token punctuation">,</span>mean<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>std<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>

<span class="token comment"># 训练并测试模型</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span>
d2l<span class="token punctuation">.</span>train_ch3<span class="token punctuation">(</span>net<span class="token punctuation">,</span>train_iter<span class="token punctuation">,</span>test_iter<span class="token punctuation">,</span>loss<span class="token punctuation">,</span>num_epochs<span class="token punctuation">,</span>batch_size<span class="token punctuation">,</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token boolean">None</span><span class="token punctuation">,</span>optimizer<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br><span class="line-number">53</span><br><span class="line-number">54</span><br><span class="line-number">55</span><br><span class="line-number">56</span><br><span class="line-number">57</span><br><span class="line-number">58</span><br><span class="line-number">59</span><br><span class="line-number">60</span><br><span class="line-number">61</span><br><span class="line-number">62</span><br><span class="line-number">63</span><br><span class="line-number">64</span><br><span class="line-number">65</span><br><span class="line-number">66</span><br><span class="line-number">67</span><br><span class="line-number">68</span><br><span class="line-number">69</span><br><span class="line-number">70</span><br><span class="line-number">71</span><br><span class="line-number">72</span><br><span class="line-number">73</span><br><span class="line-number">74</span><br><span class="line-number">75</span><br><span class="line-number">76</span><br><span class="line-number">77</span><br><span class="line-number">78</span><br><span class="line-number">79</span><br><span class="line-number">80</span><br><span class="line-number">81</span><br><span class="line-number">82</span><br><span class="line-number">83</span><br><span class="line-number">84</span><br><span class="line-number">85</span><br><span class="line-number">86</span><br><span class="line-number">87</span><br><span class="line-number">88</span><br><span class="line-number">89</span><br><span class="line-number">90</span><br><span class="line-number">91</span><br></div></div><h2 id="_3-16-实战kaggle比赛-房价预测"><a href="#_3-16-实战kaggle比赛-房价预测" class="header-anchor">#</a> 3.16 实战Kaggle比赛：房价预测</h2> <div class="language-python line-numbers-mode"><pre class="language-python"><code><span class="token comment"># 实战Kaggle比赛：房价预测</span>
<span class="token comment"># 获取和读取数据集</span>
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
<span class="token keyword">import</span> sys

<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> dataset
sys<span class="token punctuation">.</span>path<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token string">&quot;&quot;</span><span class="token punctuation">)</span>
<span class="token keyword">import</span> d2lzh_pytorch <span class="token keyword">as</span> d2l

<span class="token comment"># print(torch.__version__)</span>
torch<span class="token punctuation">.</span>set_default_tensor_type<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>FloatTensor<span class="token punctuation">)</span>

train_data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'~/Datasets/kaggle_house/train.csv'</span><span class="token punctuation">)</span>
test_data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'~/Datasets/kaggle_house/test.csv'</span><span class="token punctuation">)</span>

<span class="token comment"># print(train_data.shape)  # (1460, 81)</span>
<span class="token comment"># print(test_data.shape)   # (1459, 80)</span>
<span class="token comment"># print(train_data.iloc[0:4,[0,1,2,3,-3,-2,-1]])</span>

all_features <span class="token operator">=</span> pd<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">(</span>train_data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>test_data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># 预处理数据</span>
<span class="token comment">#获取pandas库中dataframe类型中数据类型不为object的特征的索引</span>
numeric_features <span class="token operator">=</span> all_features<span class="token punctuation">.</span>dtypes<span class="token punctuation">[</span>all_features<span class="token punctuation">.</span>dtypes<span class="token operator">!=</span><span class="token string">'object'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>index
all_features<span class="token punctuation">[</span>numeric_features<span class="token punctuation">]</span> <span class="token operator">=</span> all_features<span class="token punctuation">[</span>numeric_features<span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>
    <span class="token keyword">lambda</span> x<span class="token punctuation">:</span><span class="token punctuation">(</span>x<span class="token operator">-</span>x<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span>std<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># 标准化后，每个数值特征的均值变为0，所以可以直接用0来替换缺失值</span>
all_features<span class="token punctuation">[</span>numeric_features<span class="token punctuation">]</span> <span class="token operator">=</span> all_features<span class="token punctuation">[</span>numeric_features<span class="token punctuation">]</span><span class="token punctuation">.</span>fillna<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
<span class="token comment"># 将离散数值转成指示特征</span>
all_features <span class="token operator">=</span> pd<span class="token punctuation">.</span>get_dummies<span class="token punctuation">(</span>all_features<span class="token punctuation">,</span>dummy_na<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token comment"># print(all_features.shape)</span>
<span class="token comment"># 通过values属性得到NumPy格式的数据，并转成Tensor方便后面的训练</span>
n_train <span class="token operator">=</span> train_data<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
train_features <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>all_features<span class="token punctuation">[</span><span class="token punctuation">:</span>n_train<span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span>
test_features <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>all_features<span class="token punctuation">[</span>n_train<span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span>
train_labels <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>train_data<span class="token punctuation">.</span>SalePrice<span class="token punctuation">.</span>values<span class="token punctuation">,</span>dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>

<span class="token comment"># 训练模型</span>
loss <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">get_net</span><span class="token punctuation">(</span>feature_num<span class="token punctuation">)</span><span class="token punctuation">:</span>
    net <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>feature_num<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> param <span class="token keyword">in</span> net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        nn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>normal_<span class="token punctuation">(</span>param<span class="token punctuation">,</span>mean<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">,</span>std<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> net

<span class="token comment"># 对数均方根误差</span>
<span class="token keyword">def</span> <span class="token function">log_rmse</span><span class="token punctuation">(</span>net<span class="token punctuation">,</span>features<span class="token punctuation">,</span>labels<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 将小于1的值设成1，使得取对数时数值更稳定</span>
    clipped_preds <span class="token operator">=</span> torch<span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span>net<span class="token punctuation">(</span>features<span class="token punctuation">)</span><span class="token punctuation">,</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    rmes <span class="token operator">=</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>loss<span class="token punctuation">(</span>clipped_preds<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>labels<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> rmes<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 训练函数</span>
<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>net<span class="token punctuation">,</span>train_features<span class="token punctuation">,</span>train_labels<span class="token punctuation">,</span>test_features<span class="token punctuation">,</span>test_labels<span class="token punctuation">,</span>
            num_epochs<span class="token punctuation">,</span>learning_rate<span class="token punctuation">,</span>weight_decay<span class="token punctuation">,</span>batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
    train_ls<span class="token punctuation">,</span>test_ls <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token punctuation">]</span>
    dataset <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>TensorDataset<span class="token punctuation">(</span>train_features<span class="token punctuation">,</span>train_labels<span class="token punctuation">)</span>
    train_iter <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset<span class="token punctuation">,</span>batch_size<span class="token punctuation">,</span>shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    <span class="token comment"># 这里使用了Adam优化算法</span>
    optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>params<span class="token operator">=</span>net<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>lr <span class="token operator">=</span> learning_rate<span class="token punctuation">,</span>weight_decay<span class="token operator">=</span>weight_decay<span class="token punctuation">)</span>
    net <span class="token operator">=</span> net<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 这一步操作没看懂</span>
    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> X<span class="token punctuation">,</span>y <span class="token keyword">in</span> train_iter<span class="token punctuation">:</span>
            l <span class="token operator">=</span> loss<span class="token punctuation">(</span>net<span class="token punctuation">(</span>X<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>y<span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
            l<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
            optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        train_ls<span class="token punctuation">.</span>append<span class="token punctuation">(</span>log_rmse<span class="token punctuation">(</span>net<span class="token punctuation">,</span>train_features<span class="token punctuation">,</span>train_labels<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> test_labels <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            test_ls<span class="token punctuation">.</span>append<span class="token punctuation">(</span>log_rmse<span class="token punctuation">(</span>net<span class="token punctuation">,</span>test_features<span class="token punctuation">,</span>test_labels<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> train_ls<span class="token punctuation">,</span>test_ls

<span class="token comment"># K折交叉验证</span>
<span class="token keyword">def</span> <span class="token function">get_k_fold_data</span><span class="token punctuation">(</span>k<span class="token punctuation">,</span>i<span class="token punctuation">,</span>X<span class="token punctuation">,</span>y<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># 返回第i折交叉验证时所需要的训练和验证数据</span>
    <span class="token keyword">assert</span> k<span class="token operator">&gt;</span><span class="token number">1</span>
    fold_size <span class="token operator">=</span> X<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">//</span>k
    X_train<span class="token punctuation">,</span>y_train <span class="token operator">=</span> <span class="token boolean">None</span><span class="token punctuation">,</span><span class="token boolean">None</span>
    <span class="token keyword">for</span> j <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>k<span class="token punctuation">)</span><span class="token punctuation">:</span>
        idx <span class="token operator">=</span> <span class="token builtin">slice</span><span class="token punctuation">(</span>j<span class="token operator">*</span>fold_size<span class="token punctuation">,</span><span class="token punctuation">(</span>j<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">*</span>fold_size<span class="token punctuation">)</span>
        X_part<span class="token punctuation">,</span>y_part <span class="token operator">=</span> X<span class="token punctuation">[</span>idx<span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span><span class="token punctuation">,</span>y<span class="token punctuation">[</span>idx<span class="token punctuation">]</span>
        <span class="token keyword">if</span> j <span class="token operator">==</span> i<span class="token punctuation">:</span>
            X_valid<span class="token punctuation">,</span>y_valid <span class="token operator">=</span> X_part<span class="token punctuation">,</span>y_part
        <span class="token keyword">elif</span> X_train <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            X_train<span class="token punctuation">,</span>y_train <span class="token operator">=</span> X_part<span class="token punctuation">,</span>y_part
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            X_train <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>X_train<span class="token punctuation">,</span>X_part<span class="token punctuation">)</span><span class="token punctuation">,</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
            y_train <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>y_train<span class="token punctuation">,</span>y_part<span class="token punctuation">)</span><span class="token punctuation">,</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> X_train<span class="token punctuation">,</span>y_train<span class="token punctuation">,</span>X_valid<span class="token punctuation">,</span>y_valid

<span class="token comment"># 在K折交叉验证中我们训练K次并返回训练和验证的平均误差</span>
<span class="token keyword">def</span> <span class="token function">k_fold</span><span class="token punctuation">(</span>k<span class="token punctuation">,</span>X_train<span class="token punctuation">,</span>y_train<span class="token punctuation">,</span>num_epochs<span class="token punctuation">,</span>learning_rate<span class="token punctuation">,</span>weight_decay<span class="token punctuation">,</span>batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
    train_l_sum<span class="token punctuation">,</span>valid_l_sum <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>k<span class="token punctuation">)</span><span class="token punctuation">:</span>
        data <span class="token operator">=</span> get_k_fold_data<span class="token punctuation">(</span>k<span class="token punctuation">,</span>i<span class="token punctuation">,</span>X_train<span class="token punctuation">,</span>y_train<span class="token punctuation">)</span>
        net <span class="token operator">=</span> get_net<span class="token punctuation">(</span>X_train<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        train_ls<span class="token punctuation">,</span>valid_ls <span class="token operator">=</span> train<span class="token punctuation">(</span>net<span class="token punctuation">,</span><span class="token operator">*</span>data<span class="token punctuation">,</span>num_epochs<span class="token punctuation">,</span>learning_rate<span class="token punctuation">,</span>weight_decay<span class="token punctuation">,</span>batch_size<span class="token punctuation">)</span>
        train_l_sum <span class="token operator">+=</span> train_ls<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
        valid_l_sum <span class="token operator">+=</span> valid_ls<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>
        <span class="token keyword">if</span> i<span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">:</span>
            d2l<span class="token punctuation">.</span>semilogy<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>num_epochs<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>train_ls<span class="token punctuation">,</span><span class="token string">'epochs'</span><span class="token punctuation">,</span><span class="token string">'rmse'</span><span class="token punctuation">,</span>
                        <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>num_epochs<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>valid_ls<span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">,</span><span class="token string">'valid'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'flod %d, train rmse %f, valid rmse %f'</span><span class="token operator">%</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span>train_ls<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>valid_ls<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>   
    <span class="token keyword">return</span> train_l_sum<span class="token operator">/</span>k<span class="token punctuation">,</span>valid_l_sum<span class="token operator">/</span>k

<span class="token comment"># 模型选择</span>
k<span class="token punctuation">,</span>num_epochs<span class="token punctuation">,</span>lr<span class="token punctuation">,</span>weight_decay<span class="token punctuation">,</span>batch_size <span class="token operator">=</span> <span class="token number">5</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">64</span>
<span class="token comment"># train_l,valid_l = k_fold(k,train_features,train_labels,num_epochs,lr,weight_decay,batch_size)</span>
<span class="token comment"># print('%d-fold validation:avg train rmse %f,avg valid rmse %f'%(k,train_l,valid_l))</span>

<span class="token comment"># 预测并在Kaggle提交结果</span>
<span class="token keyword">def</span> <span class="token function">train_and_pred</span><span class="token punctuation">(</span>train_features<span class="token punctuation">,</span>test_features<span class="token punctuation">,</span>train_labels<span class="token punctuation">,</span>test_data<span class="token punctuation">,</span>num_epochs<span class="token punctuation">,</span>lr<span class="token punctuation">,</span>weight_decay<span class="token punctuation">,</span>batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>
    net <span class="token operator">=</span> get_net<span class="token punctuation">(</span>train_features<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    train_ls<span class="token punctuation">,</span>_ <span class="token operator">=</span> train<span class="token punctuation">(</span>net<span class="token punctuation">,</span>train_features<span class="token punctuation">,</span>train_labels<span class="token punctuation">,</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token boolean">None</span><span class="token punctuation">,</span>num_epochs<span class="token punctuation">,</span>lr<span class="token punctuation">,</span>weight_decay<span class="token punctuation">,</span>batch_size<span class="token punctuation">)</span>
    d2l<span class="token punctuation">.</span>semilogy<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>num_epochs<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>train_ls<span class="token punctuation">,</span><span class="token string">'epochs'</span><span class="token punctuation">,</span><span class="token string">'rmse'</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'train rmse %f'</span> <span class="token operator">%</span> train_ls<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token comment"># tensor.detach()返回一个新的tensor,requires_grad为false</span>
    preds <span class="token operator">=</span> net<span class="token punctuation">(</span>test_features<span class="token punctuation">)</span><span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
    test_data<span class="token punctuation">[</span><span class="token string">'SalePrice'</span><span class="token punctuation">]</span><span class="token operator">=</span>pd<span class="token punctuation">.</span>Series<span class="token punctuation">(</span>preds<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    submission <span class="token operator">=</span> pd<span class="token punctuation">.</span>concat<span class="token punctuation">(</span><span class="token punctuation">[</span>test_data<span class="token punctuation">[</span><span class="token string">'Id'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>test_data<span class="token punctuation">[</span><span class="token string">'SalePrice'</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
    submission<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span><span class="token string">'./submission.csv'</span><span class="token punctuation">,</span>index<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>  <span class="token comment"># 生成提交需要的csv格式文件</span>

train_and_pred<span class="token punctuation">(</span>train_features<span class="token punctuation">,</span>test_features<span class="token punctuation">,</span>train_labels<span class="token punctuation">,</span>test_data<span class="token punctuation">,</span>num_epochs<span class="token punctuation">,</span>lr<span class="token punctuation">,</span>weight_decay<span class="token punctuation">,</span>batch_size<span class="token punctuation">)</span>
</code></pre> <div class="line-numbers-wrapper"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br><span class="line-number">29</span><br><span class="line-number">30</span><br><span class="line-number">31</span><br><span class="line-number">32</span><br><span class="line-number">33</span><br><span class="line-number">34</span><br><span class="line-number">35</span><br><span class="line-number">36</span><br><span class="line-number">37</span><br><span class="line-number">38</span><br><span class="line-number">39</span><br><span class="line-number">40</span><br><span class="line-number">41</span><br><span class="line-number">42</span><br><span class="line-number">43</span><br><span class="line-number">44</span><br><span class="line-number">45</span><br><span class="line-number">46</span><br><span class="line-number">47</span><br><span class="line-number">48</span><br><span class="line-number">49</span><br><span class="line-number">50</span><br><span class="line-number">51</span><br><span class="line-number">52</span><br><span class="line-number">53</span><br><span class="line-number">54</span><br><span class="line-number">55</span><br><span class="line-number">56</span><br><span class="line-number">57</span><br><span class="line-number">58</span><br><span class="line-number">59</span><br><span class="line-number">60</span><br><span class="line-number">61</span><br><span class="line-number">62</span><br><span class="line-number">63</span><br><span class="line-number">64</span><br><span class="line-number">65</span><br><span class="line-number">66</span><br><span class="line-number">67</span><br><span class="line-number">68</span><br><span class="line-number">69</span><br><span class="line-number">70</span><br><span class="line-number">71</span><br><span class="line-number">72</span><br><span class="line-number">73</span><br><span class="line-number">74</span><br><span class="line-number">75</span><br><span class="line-number">76</span><br><span class="line-number">77</span><br><span class="line-number">78</span><br><span class="line-number">79</span><br><span class="line-number">80</span><br><span class="line-number">81</span><br><span class="line-number">82</span><br><span class="line-number">83</span><br><span class="line-number">84</span><br><span class="line-number">85</span><br><span class="line-number">86</span><br><span class="line-number">87</span><br><span class="line-number">88</span><br><span class="line-number">89</span><br><span class="line-number">90</span><br><span class="line-number">91</span><br><span class="line-number">92</span><br><span class="line-number">93</span><br><span class="line-number">94</span><br><span class="line-number">95</span><br><span class="line-number">96</span><br><span class="line-number">97</span><br><span class="line-number">98</span><br><span class="line-number">99</span><br><span class="line-number">100</span><br><span class="line-number">101</span><br><span class="line-number">102</span><br><span class="line-number">103</span><br><span class="line-number">104</span><br><span class="line-number">105</span><br><span class="line-number">106</span><br><span class="line-number">107</span><br><span class="line-number">108</span><br><span class="line-number">109</span><br><span class="line-number">110</span><br><span class="line-number">111</span><br><span class="line-number">112</span><br><span class="line-number">113</span><br><span class="line-number">114</span><br><span class="line-number">115</span><br><span class="line-number">116</span><br><span class="line-number">117</span><br><span class="line-number">118</span><br><span class="line-number">119</span><br><span class="line-number">120</span><br><span class="line-number">121</span><br><span class="line-number">122</span><br><span class="line-number">123</span><br><span class="line-number">124</span><br><span class="line-number">125</span><br><span class="line-number">126</span><br><span class="line-number">127</span><br></div></div></div> <footer class="page-edit"><!----> <div class="last-updated"><span class="prefix">更新时间:</span> <span class="time">11/23/2021, 9:21:51 PM</span></div></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/studybook/Dive-into-DL/d2lzh_pytorch.html" class="prev">
        d2lzh_pytorch
      </a></span> <span class="next"><a href="/studybook/Dive-into-DL/第四章.html">
        第四章
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.a00dae28.js" defer></script><script src="/assets/js/2.6ba3a72f.js" defer></script><script src="/assets/js/14.3fbb62f4.js" defer></script>
  </body>
</html>
